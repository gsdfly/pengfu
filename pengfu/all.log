2018-12-14 11:09:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:09:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:09:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:09:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:09:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:09:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:09:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:09:54 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:09:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:09:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:09:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:09:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:09:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 14, in parse
    print(name.text)
AttributeError: 'SelectorList' object has no attribute 'text'
2018-12-14 11:09:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:09:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7470,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 9, 56, 856721),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 9, 54, 643742)}
2018-12-14 11:09:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:10:12 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:10:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:10:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:10:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:10:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:10:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:10:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:10:13 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:10:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:10:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:10:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:10:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 15, in parse
    print(name.text)
AttributeError: 'SelectorList' object has no attribute 'text'
2018-12-14 11:10:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:10:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7463,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 10, 15, 386044),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 10, 13, 123028)}
2018-12-14 11:10:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:10:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:10:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:10:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:10:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:10:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:10:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:10:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:10:26 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:10:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:10:26 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:10:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:10:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:10:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:10:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7466,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 10, 28, 621061),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 10, 26, 464323)}
2018-12-14 11:10:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:10:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:10:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:10:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:10:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:10:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:10:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:10:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:10:57 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:10:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:10:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:10:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:10:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:10:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:10:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7463,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 10, 59, 860782),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 10, 57, 699860)}
2018-12-14 11:10:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:12:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:12:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:12:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:12:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:12:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:12:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:12:45 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:12:45 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:12:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:12:45 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:12:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:12:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:12:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:12:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7465,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 12, 47, 849524),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 12, 45, 671737)}
2018-12-14 11:12:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:14:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:14:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:14:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:14:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:14:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:14:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:14:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:14:29 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:14:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:14:29 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:14:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:14:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:14:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 22, in parse
    content = item.css('.content-img::text').extracr()
AttributeError: 'SelectorList' object has no attribute 'extracr'
2018-12-14 11:14:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:14:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7472,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 14, 31, 597968),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 14, 29, 310642)}
2018-12-14 11:14:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:15:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:15:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:15:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:15:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:15:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:15:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:15:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:15:03 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:15:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:15:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:15:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:15:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:15:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:15:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7473,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 15, 6, 322141),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 15, 3, 97565)}
2018-12-14 11:15:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:17:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:17:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:17:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:17:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:17:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:17:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:17:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:17:07 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:17:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:17:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:17:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:17:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7472,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 17, 9, 338641),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 17, 7, 176893)}
2018-12-14 11:17:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:17:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:17:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:17:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:17:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:17:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:17:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:17:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:17:38 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:17:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:17:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:17:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:17:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:17:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 14, in parse
    name = item.css('.user_name_list::text').extract()[0]
IndexError: list index out of range
2018-12-14 11:17:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:17:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7473,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 17, 40, 368299),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 17, 38, 145591)}
2018-12-14 11:17:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:27:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:27:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:27:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:27:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:27:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:27:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:27:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:27:30 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:27:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:27:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:27:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:27:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:27:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7473,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 27, 33, 38800),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 27, 30, 758383)}
2018-12-14 11:27:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:29:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:29:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:29:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:29:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:29:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:29:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:29:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:29:53 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:29:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:29:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:29:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:29:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:29:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:29:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 29, 55, 370932),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 29, 53, 97890)}
2018-12-14 11:29:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:31:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:31:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:31:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:31:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:31:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:31:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:31:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:31:42 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:31:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:31:42 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:31:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:31:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:31:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:31:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7468,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 31, 45, 761731),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 31, 42, 569240)}
2018-12-14 11:31:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:33:07 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:33:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:33:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:33:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:33:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:33:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:33:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:33:07 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:33:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:33:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:33:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:33:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 33, 10, 115882),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 33, 7, 932073)}
2018-12-14 11:33:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:33:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:33:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:33:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:33:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:33:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:33:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:33:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:33:26 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:33:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:33:26 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:33:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:33:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:33:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:33:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 33, 29, 172966),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 33, 26, 995274)}
2018-12-14 11:33:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:34:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:34:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:34:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:34:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:34:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:34:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:34:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:34:25 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:34:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:34:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:34:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:34:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7468,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 34, 27, 614775),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 34, 25, 439004)}
2018-12-14 11:34:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:35:21 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:35:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:35:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:35:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:35:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:35:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:35:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:35:22 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:35:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:35:22 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:35:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:35:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:35:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:35:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 35, 24, 478988),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 35, 22, 308213)}
2018-12-14 11:35:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:35:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:35:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:35:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:35:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:35:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:35:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:35:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:35:47 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:35:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:35:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:35:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:35:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:35:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 35, 49, 885028),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 35, 47, 711171)}
2018-12-14 11:35:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:36:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:36:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:36:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:36:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:36:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:36:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:36:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:36:07 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:36:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:36:07 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:36:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:36:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7465,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 36, 9, 414597),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 36, 7, 258865)}
2018-12-14 11:36:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:36:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:36:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:36:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:36:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:36:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:36:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:36:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:36:27 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:36:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:36:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:36:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:36:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7468,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 36, 29, 362621),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 36, 27, 221422)}
2018-12-14 11:36:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:36:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:36:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:36:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:36:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:36:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:36:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:36:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:36:55 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:36:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:36:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:36:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:36:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:36:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 36, 57, 297946),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 36, 55, 162229)}
2018-12-14 11:36:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:38:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:38:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:38:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:38:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:38:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:38:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:38:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:38:19 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:38:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:38:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:38:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:38:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7465,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 38, 21, 185274),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 38, 19, 46366)}
2018-12-14 11:38:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:40:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:40:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:40:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:40:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:40:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:40:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:40:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:40:36 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:40:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:40:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:40:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:40:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:40:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:40:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 40, 38, 902692),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 40, 36, 692815)}
2018-12-14 11:40:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:41:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:41:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:41:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:41:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:41:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:41:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:41:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:41:28 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:41:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:41:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:41:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:41:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 18, in parse
    content_img = item.css('.content-img img::attr(src)').extract()[0]
IndexError: list index out of range
2018-12-14 11:41:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:41:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7469,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 41, 32, 769171),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 41, 28, 826024)}
2018-12-14 11:41:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:46:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:46:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:46:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:46:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:46:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:46:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:46:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:46:10 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:46:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:46:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:46:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:46:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:46:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 17, in parse
    penfuItem['img'] = ''
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'PengfuItem does not support field: img'
2018-12-14 11:46:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:46:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7475,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 46, 13, 241748),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 46, 10, 949080)}
2018-12-14 11:46:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:46:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:46:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:46:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:46:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:46:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:46:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:46:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:46:50 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:46:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:46:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:46:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:46:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:46:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:46:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7472,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 46, 52, 213158),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 46, 50, 42001)}
2018-12-14 11:46:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:53:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:53:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:53:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:53:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:53:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:53:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:53:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:53:18 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:53:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:53:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:53:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:53:23 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://www.pengfu.com/zuijurenqi_1_2.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-12-14 11:53:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2018-12-14 11:53:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:53:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 777,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 14325,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 53, 25, 83003),
 'log_count/DEBUG': 5,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 12, 14, 3, 53, 18, 135469)}
2018-12-14 11:53:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:54:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:54:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:54:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:54:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:54:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:54:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:54:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:54:06 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:54:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:54:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:54:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:54:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:54:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2018-12-14 11:54:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:54:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 777,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 14318,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 54, 9, 711740),
 'log_count/DEBUG': 4,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 12, 14, 3, 54, 6, 507608)}
2018-12-14 11:54:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:55:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:55:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:55:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:55:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:55:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:55:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:55:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:55:18 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:55:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:55:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:55:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:55:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:55:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\spiders\remen.py", line 22, in parse
    isNext = response.css('.page a.on::text').extract_last().strip()
AttributeError: 'SelectorList' object has no attribute 'extract_last'
2018-12-14 11:55:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:55:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7455,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 55, 20, 659043),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 12, 14, 3, 55, 18, 488212)}
2018-12-14 11:55:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 11:58:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 11:58:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 11:58:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 11:58:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 11:58:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 11:58:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 11:58:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 11:58:19 [scrapy.core.engine] INFO: Spider opened
2018-12-14 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 11:58:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 11:58:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 11:58:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 11:58:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2018-12-14 11:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2018-12-14 11:58:23 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://www.pengfu.com/zuijurenqi_1_2.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-12-14 11:58:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 11:58:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1099,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 21458,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 3, 58, 23, 913469),
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'request_depth_max': 3,
 'response_received_count': 4,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 14, 3, 58, 19, 426474)}
2018-12-14 11:58:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 12:04:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 12:04:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 12:04:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 12:04:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 12:04:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 12:04:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 12:04:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 12:04:56 [scrapy.core.engine] INFO: Spider opened
2018-12-14 12:04:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 12:04:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 12:04:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 12:04:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 12:04:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2018-12-14 12:05:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2018-12-14 12:05:00 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://www.pengfu.com/zuijurenqi_1_2.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-12-14 12:05:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 12:05:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1099,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 21476,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 4, 5, 0, 499985),
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'request_depth_max': 3,
 'response_received_count': 4,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 14, 4, 4, 56, 68388)}
2018-12-14 12:05:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 12:05:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 12:05:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 12:05:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 12:05:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 12:05:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 12:05:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 12:05:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 12:05:24 [scrapy.core.engine] INFO: Spider opened
2018-12-14 12:05:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 12:05:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 12:05:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 12:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: None)
2018-12-14 12:05:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 12:05:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7174,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 4, 5, 26, 577217),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 4, 5, 24, 341688)}
2018-12-14 12:05:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 12:05:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 12:05:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 12:05:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 12:05:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 12:05:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 12:05:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 12:05:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 12:05:38 [scrapy.core.engine] INFO: Spider opened
2018-12-14 12:05:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 12:05:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 12:05:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 12:05:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: None)
2018-12-14 12:05:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 12:05:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7174,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 4, 5, 41, 25667),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 4, 5, 38, 796220)}
2018-12-14 12:05:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 12:05:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 12:05:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 12:05:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 12:05:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 12:05:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 12:05:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 12:05:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 12:05:59 [scrapy.core.engine] INFO: Spider opened
2018-12-14 12:05:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 12:05:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 12:06:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 12:06:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: None)
2018-12-14 12:06:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 12:06:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 455,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7180,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 4, 6, 1, 778252),
 'log_count/DEBUG': 3,
 'log_count/INFO': 7,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 4, 5, 59, 566808)}
2018-12-14 12:06:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 12:06:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 12:06:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 12:06:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['pengfu.spiders']}
2018-12-14 12:06:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 12:06:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 12:06:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 12:06:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-14 12:06:57 [scrapy.core.engine] INFO: Spider opened
2018-12-14 12:06:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 12:06:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 12:06:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/robots.txt> (referer: None)
2018-12-14 12:06:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 12:07:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2018-12-14 12:07:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_3.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2018-12-14 12:07:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 12:07:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1099,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 20327,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 4, 7, 1, 175800),
 'log_count/DEBUG': 5,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 14, 4, 6, 57, 135863)}
2018-12-14 12:07:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 14:14:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 14:14:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 14:14:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2018-12-14 14:14:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 14:14:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 14:14:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 14:14:18 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2018-12-14 14:14:18 [scrapy.core.engine] INFO: Spider opened
2018-12-14 14:14:18 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-14 14:14:18 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\crawler.py", line 82, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
TypeError: open_spider() takes 1 positional argument but 2 were given

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
TypeError: close_spider() takes 1 positional argument but 2 were given
2018-12-14 14:14:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 12, 14, 6, 14, 18, 264714),
 'log_count/ERROR': 1,
 'log_count/INFO': 6}
2018-12-14 14:14:18 [scrapy.core.engine] INFO: Spider closed (shutdown)
2018-12-14 14:14:18 [twisted] CRITICAL: Unhandled error in Deferred:
2018-12-14 14:14:18 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\crawler.py", line 82, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
TypeError: open_spider() takes 1 positional argument but 2 were given
2018-12-14 14:15:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 14:15:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 14:15:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2018-12-14 14:15:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 14:15:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 14:15:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 14:15:18 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2018-12-14 14:15:18 [scrapy.core.engine] INFO: Spider opened
2018-12-14 14:15:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 14:15:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 14:15:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '我例行检查儿子的作业，作文题目《我的妈妈》。儿子写道:孩子是遗落人间的明珠，而妈妈本应是上帝派来保护孩子的天使。而我却是上帝掉落的陀螺，我妈妈则是那个喜欢抽陀螺的魔鬼……',
 'img': '',
 'name': '何大宝',
 'title': '我看这孩子平时确实是抽少了 '}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181213/5c12156766fbf.jpg',
 'name': '何大宝',
 'title': '你哥哥真的是狠优秀！'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '我带上你，你带上碗，你负责哭，我负责喊，找个旅游景点，一起当老板！',
 'img': 'https://image7.pengfu.com/origin/181213/5c12158dbed74.jpg',
 'name': '何大宝',
 'title': '年底将至：'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c1211cd7cda1.jpg',
 'name': '何大宝',
 'title': '店庆大酬宾，吃饭送泡脚'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120a6f34625.jpg',
 'name': '何大宝',
 'title': '会用面包屑耐心“钓”鱼的金毛'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120de2be7e5.jpg',
 'name': '何大宝',
 'title': '可不敢乱玩了'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a2916372.jpg',
 'name': '何大宝',
 'title': '双胞胎姐妹傻傻分不清'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120e0377cfb.jpg',
 'name': '何大宝',
 'title': '没人注意到第五个妹子吗？'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a4eace8f.jpg',
 'name': '何大宝',
 'title': '无师自通，佩服佩服'}
2018-12-14 14:15:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a408861f.jpg',
 'name': '何大宝',
 'title': '掉个头有那么难吗？'}
2018-12-14 14:15:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120e0bf238e.jpg',
 'name': '何大宝',
 'title': '我家的跑步机好几十万买的'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a346c4f1.jpg',
 'name': '何大宝',
 'title': '如今干瓦匠要这么高的技巧了'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120de99d99d.jpg',
 'name': '何大宝',
 'title': '耳朵凑过来，跟你说句话'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120dce9da21.jpg',
 'name': '何大宝',
 'title': '我有夹娃娃的特殊技巧'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120dd74fa07.jpg',
 'name': '何大宝',
 'title': '姑娘技术不过硬别耍酷'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c1209f27d55b.jpg',
 'name': '何大宝',
 'title': '我也要许这样的愿'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120daf375dd.jpg',
 'name': '何大宝',
 'title': '.车都扁了，大哥完好无损太幸运了'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120a20c19db.jpg',
 'name': '何大宝',
 'title': '都不能好生洗个头'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a10c774e.jpg',
 'name': '何大宝',
 'title': '逗你玩～'}
2018-12-14 14:15:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120a00502a2.jpg',
 'name': '何大宝',
 'title': '这一跳，这个运动员差点退役'}
2018-12-14 14:15:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_3.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2018-12-14 14:15:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a1d19db7.jpg',
 'name': '何大宝',
 'title': '这是典型的众女轻男啊'}
2018-12-14 14:15:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120dd738688.jpg',
 'name': '何大宝',
 'title': '这是谁媳妇，又调皮了'}
2018-12-14 14:15:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '，看来真的是我想多了',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120d9d95d90.jpg',
 'name': '何大宝',
 'title': '还以为这位小哥真的这么高'}
2018-12-14 14:15:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181214/5c12f2e1e816f.jpg',
 'name': '粉色娘子军',
 'title': '揣着明白装糊涂'}
2018-12-14 14:15:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 14:15:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1137,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 20302,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 6, 15, 22, 325899),
 'item_scraped_count': 24,
 'log_count/DEBUG': 28,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 14, 6, 15, 18, 435034)}
2018-12-14 14:15:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 14:36:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 14:36:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 14:36:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2018-12-14 14:36:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 14:36:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 14:36:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 14:36:23 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2018-12-14 14:36:23 [scrapy.core.engine] INFO: Spider opened
2018-12-14 14:36:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 14:36:23 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 14:36:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '我例行检查儿子的作业，作文题目《我的妈妈》。儿子写道:孩子是遗落人间的明珠，而妈妈本应是上帝派来保护孩子的天使。而我却是上帝掉落的陀螺，我妈妈则是那个喜欢抽陀螺的魔鬼……',
 'img': '',
 'name': '何大宝',
 'title': '我看这孩子平时确实是抽少了 '}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181213/5c12156766fbf.jpg',
 'name': '何大宝',
 'title': '你哥哥真的是狠优秀！'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '我带上你，你带上碗，你负责哭，我负责喊，找个旅游景点，一起当老板！',
 'img': 'https://image7.pengfu.com/origin/181213/5c12158dbed74.jpg',
 'name': '何大宝',
 'title': '年底将至：'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181214/5c12f2e1e816f.jpg',
 'name': '粉色娘子军',
 'title': '揣着明白装糊涂'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c1211cd7cda1.jpg',
 'name': '何大宝',
 'title': '店庆大酬宾，吃饭送泡脚'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c12f185b74bb.jpg',
 'name': '粉色娘子军',
 'title': '就是要弹，弹，弹'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c12f193d1f19.jpg',
 'name': '粉色娘子军',
 'title': '年轻人!生活不是这样过的'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120a6f34625.jpg',
 'name': '何大宝',
 'title': '会用面包屑耐心“钓”鱼的金毛'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120de2be7e5.jpg',
 'name': '何大宝',
 'title': '可不敢乱玩了'}
2018-12-14 14:36:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a2916372.jpg',
 'name': '何大宝',
 'title': '双胞胎姐妹傻傻分不清'}
2018-12-14 14:36:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 14:36:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7340,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 6, 36, 24, 912318),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 14, 6, 36, 23, 124144)}
2018-12-14 14:36:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-14 14:38:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2018-12-14 14:38:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2018-12-14 14:38:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2018-12-14 14:38:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-14 14:38:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-14 14:38:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-14 14:38:53 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2018-12-14 14:38:53 [scrapy.core.engine] INFO: Spider opened
2018-12-14 14:38:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-14 14:38:53 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-12-14 14:38:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: None)
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120e0377cfb.jpg',
 'name': '何大宝',
 'title': '没人注意到第五个妹子吗？'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a4eace8f.jpg',
 'name': '何大宝',
 'title': '无师自通，佩服佩服'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a408861f.jpg',
 'name': '何大宝',
 'title': '掉个头有那么难吗？'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120e0bf238e.jpg',
 'name': '何大宝',
 'title': '我家的跑步机好几十万买的'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a346c4f1.jpg',
 'name': '何大宝',
 'title': '如今干瓦匠要这么高的技巧了'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120de99d99d.jpg',
 'name': '何大宝',
 'title': '耳朵凑过来，跟你说句话'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120dce9da21.jpg',
 'name': '何大宝',
 'title': '我有夹娃娃的特殊技巧'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120dd74fa07.jpg',
 'name': '何大宝',
 'title': '姑娘技术不过硬别耍酷'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c1209f27d55b.jpg',
 'name': '何大宝',
 'title': '我也要许这样的愿'}
2018-12-14 14:38:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120daf375dd.jpg',
 'name': '何大宝',
 'title': '.车都扁了，大哥完好无损太幸运了'}
2018-12-14 14:38:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_3.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120a20c19db.jpg',
 'name': '何大宝',
 'title': '都不能好生洗个头'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a10c774e.jpg',
 'name': '何大宝',
 'title': '逗你玩～'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120a00502a2.jpg',
 'name': '何大宝',
 'title': '这一跳，这个运动员差点退役'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c120a1d19db7.jpg',
 'name': '何大宝',
 'title': '这是典型的众女轻男啊'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '，看来真的是我想多了',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120d9d95d90.jpg',
 'name': '何大宝',
 'title': '还以为这位小哥真的这么高'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c120dd738688.jpg',
 'name': '何大宝',
 'title': '这是谁媳妇，又调皮了'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c12f28cb752a.jpg',
 'name': '粉色娘子军',
 'title': '我是这个十分低调的人，从来不炫富'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c12f27f74549.jpg',
 'name': '粉色娘子军',
 'title': '莫非深藏不露'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c12f26571f2e.jpg',
 'name': '粉色娘子军',
 'title': '这是见面礼吗'}
2018-12-14 14:38:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c12f1b9a2cb1.jpg',
 'name': '粉色娘子军',
 'title': '电视里面有什么'}
2018-12-14 14:38:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_4.html> (referer: https://www.pengfu.com/zuijurenqi_1_3.html)
2018-12-14 14:38:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c12f1eac69c0.jpg',
 'name': '粉色娘子军',
 'title': '偶尔和陌生人之间的莫名小默契'}
2018-12-14 14:38:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c12f1d98b092.jpg',
 'name': '粉色娘子军',
 'title': '那深情的一笑让我对你的好感荡然无存'}
2018-12-14 14:38:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c12f1a22dd26.jpg',
 'name': '粉色娘子军',
 'title': '牛顿的棺材我按住了，你们继续'}
2018-12-14 14:38:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c12f1cc2120a.jpg',
 'name': '粉色娘子军',
 'title': '不意外的话，坟头草该腰高了'}
2018-12-14 14:38:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c12f2722faa7.jpg',
 'name': '粉色娘子军',
 'title': '地中海救星'}
2018-12-14 14:38:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c12f15b254ce.jpg',
 'name': '粉色娘子军',
 'title': '好美的一张图，大家慢慢欣赏吧'}
2018-12-14 14:38:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-14 14:38:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1137,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 20292,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 14, 6, 38, 57, 86820),
 'item_scraped_count': 26,
 'log_count/DEBUG': 30,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 14, 6, 38, 53, 116548)}
2018-12-14 14:38:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-09 17:55:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-09 17:55:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-09 17:55:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-09 17:55:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-01-09 17:55:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-09 17:55:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-09 17:55:54 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-09 17:55:54 [scrapy.core.engine] INFO: Spider opened
2019-01-09 17:55:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-09 17:55:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-09 17:55:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_1.html> (referer: None)
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181227/5c245dc22260b.jpg',
 'name': '采妮',
 'title': '古时古诗固是故事？'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181230/5c28880155c99.jpg',
 'name': '何大宝',
 'title': '捧友们给个建议吧'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181222/5c1df0a3ac9e6.jpg',
 'name': '何大宝',
 'title': '这道菜能起个文艺点的名字吗？'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181228/5c25bd0ba6847.jpg',
 'name': '采妮',
 'title': '路见不平？'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190102/5c2bfd1e0d416.jpg',
 'name': '采妮',
 'title': '鱼：你们快点吃，'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181222/5c1df13d9f524.jpg',
 'name': '何大宝',
 'title': '男人的败类！'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181217/5c1729f986973.jpg',
 'name': '采妮',
 'title': '换了我也会果断放弃'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181228/5c25d94b53ae9.jpg',
 'name': '何大宝',
 'title': '难割难舍的摊位......'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181223/5c1f4da63323f.jpg',
 'name': '何大宝',
 'title': '新买的鞋子，好看么！'}
2019-01-09 17:55:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_1.html>
{'content': '近日民警在义乌火车站巡逻时，发现一名男子身穿一件黑色卫衣，胸前印着“逍遥法外”四个大字。于是上前要求他出示有效身份证件，结果发现该男子系网上在逃人员。',
 'img': 'https://image7.pengfu.com/origin/181220/5c1b57daee825.jpg',
 'name': '何大宝',
 'title': '这就是得瑟的下场'}
2019-01-09 17:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_2.html> (referer: https://www.pengfu.com/zuijurenqi_30_1.html)
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190102/5c2c7b4b2f70e.jpg',
 'name': '何大宝',
 'title': '这个发现震惊了世界'}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190105/5c2ff49eabf3f.jpg',
 'name': '采妮',
 'title': '终是二楼为人才，捧腹大神续起来！'}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181226/5c233fa906e57.jpg',
 'name': '何大宝',
 'title': '吃披萨要什么文凭！'}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181221/5c1ca873cdec6.jpg',
 'name': '何大宝',
 'title': '这是真的吗？有没有一起去的'}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '我们村里何老二的老婆生孩子。孩子出生了。是个残疾。只有一只腿。何老二当时就纳闷了:几亿小蝌蚪中，你TM缺条腿，也能跑第一?长大必是奇才啊，从此对这孩子倍加呵护。',
 'img': '',
 'name': '何大宝',
 'title': '天生奇才必有用 '}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '那年，家族聚餐，四岁大的侄子却一直拉肚子，说屁屁都拉疼了。我把他抱起来，晾开屁屁，放在风扇前吹：“这样屁屁舒服了吧？”侄子眉头舒开，突然一股黄流从他屁屁激射到风扇上，旋开，扫射到饭厅毎个角落！我哥埋头夹着肉丸子，还没发现这一切，只是说了一句：“奇怪，我的肉丸子啥时候蘸了花生酱？”侄子依然不消停，一股接一股射过去...风扇还是摇头的，顿时黄雾弥漫，大家雨露均沾！我把侄子转过来，他又把餐桌上一碗汤射成蛋花汤...“快把枪放下！”我爸惊慌的辞不达意的对我吼道！我把侄子放地上，把风扇关了，饭厅一片狼藉，大家尖叫一片...天花板都有不少黄酱摇摇欲滴...我把侄子带到洗手间，里面传出我哥的呕吐声：“老子再也不吃蘸酱的肉丸...”那一天，大家都很忙，打扫卫生，当然最忙的是洗手间。每个人都去洗手间洗衣服洗澡，我姐刚洗完，出来仰天长啸，又给天花板滴落的黄酱滴到，只好再洗一次...老爸最后发话，这事八年都不许说，今天正好八年过去了，发文以记之...',
 'img': '',
 'name': '何大宝',
 'title': '不寒而栗的往事 '}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '大学时交了一个男朋友，一晚约了吃饭看电影，我精心打扮了整整一个下午，看完电影晚上十点半了，他竟然说送我回宿舍，我就陪着他磨磨蹭蹭往回走，回到宿舍大门已经十一点十分，锁门了，于是他带我到后面小门，也已经锁了。他有点紧张的问我：“我没带身份证，你带了吗？”天啊，他终于开窍了。我兴奋的告诉他：“我带了。”他说：“太好了。”于是，他用我的证件插进门缝里，把门打开了！',
 'img': '',
 'name': '采妮',
 'title': '宁插门也不插人 '}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190107/5c32918bcca75.jpg',
 'name': '何大宝',
 'title': '婆婆最终还是嫌弃我！'}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181225/5c217367e1f8d.jpg',
 'name': '粉色娘子军',
 'title': '我突然不会解这个题了？'}
2019-01-09 17:55:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_2.html>
{'content': '终于你给我穿上雪白的婚纱',
 'img': 'https://image6.pengfu.com/origin/181228/5c25672bbf979.jpg',
 'name': '粉色娘子军',
 'title': '从穿上军装那一天开始等你'}
2019-01-09 17:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_3.html> (referer: https://www.pengfu.com/zuijurenqi_30_2.html)
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181229/5c26c7232f103.jpg',
 'name': '采妮',
 'title': '来一个吧，超值'}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181220/5c1b03ed1de2c.png',
 'name': '2925112454',
 'title': '我现在的财富，离不开我这几年的不断努力！'}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190104/5c2f2719e4abd.jpg',
 'name': '何大宝',
 'title': '别睡了，快醒醒吧！天都亮了'}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '今天冬至，没有饺子没有羊肉汤，自己买了一袋恰恰香瓜子，我一个人嗑完了，一共1854颗，26颗是空的，混进来9颗带虫的，有6颗没炒开，是连在一起的，还有4个是苦的。中间喝了7杯水。没错，这就是孤独。----刚刚这段话一共62个字，11个标点符号，其中横116划，竖137划，撇65划，捺57划，其他139划……',
 'img': '',
 'name': '采妮',
 'title': '告诉你什么叫孤独   '}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190101/5c2abb42b3cb4.jpg',
 'name': '采妮',
 'title': '新套路！'}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181225/5c21859f94c3f.jpg',
 'name': '采妮',
 'title': '房东说那只是一个水印？'}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '快过年了，跟媳妇一家一起去她远方的姥姥家。到了她的一个亲戚家里，有个四五岁的小姑娘，长得很可爱。我上去就摸着她的头说：小妹妹真可爱。。。然后丈母娘在旁边冷冷地说了句：没大没小的，她是你姨姥姥。。。',
 'img': '',
 'name': '何大宝',
 'title': '孙子，你再摸我头试试   '}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '坐火车遇到一个安徽人问我：你们四川人是不是都会变脸啊？我反问道：那你们安徽人是不是都唱黄梅戏？然后…然后她给我唱了一段黄梅戏…唱完后她得意的说：我唱了，你倒是变啊？我脸色一变：滚…',
 'img': '',
 'name': '何大宝',
 'title': '我们四川人决不示弱   '}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '往暖壶里灌的时候，突然发现脚上落了一只苍蝇，就想烫死它……去医院时我爸得知我怎么烫的之后，沉默了一会说，先挂精神障碍科吧！',
 'img': 'https://image6.pengfu.com/origin/181226/5c233f07aa613.jpg',
 'name': '何大宝',
 'title': '烧了壶开水，'}
2019-01-09 17:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1ca34e7fac0.jpg',
 'name': '何大宝',
 'title': '这个我上我也行！'}
2019-01-09 17:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_4.html> (referer: https://www.pengfu.com/zuijurenqi_30_3.html)
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '有家洗脚店要装修，我去量尺寸、谈条件，一直倒腾到晚上九点，出来时太累就打了出租。回到小区门口下车，遇到老婆在买烧烤，她走过来问司机：“师傅，他在哪里上车的？”司机看看我俩，说：“新华书店。”然后一踩油门走了。',
 'img': '',
 'name': '何大宝',
 'title': '还是男人了解男人  '}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2884d6a82a1.jpg',
 'name': '何大宝',
 'title': '不是每个女生都能穿出这种效果'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181223/5c1f4e0521fb5.jpg',
 'name': '何大宝',
 'title': '悲哀的是这是很常见的事'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181212/5c10528244e35.jpg',
 'name': '粉色娘子军',
 'title': '双胎嫁给了双胞胎然后又分别生了双胞胎.'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328eceb5fc1.jpg',
 'name': '何大宝',
 'title': '农民工真的太不容易了'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190104/5c2ec7da4d3f3.jpg',
 'name': '采妮',
 'title': '鬼才'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181221/5c1c3c977fdc7.jpg',
 'name': '粉色娘子军',
 'title': '这或许就是真爱吧'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181219/5c19990e2caa0.jpg',
 'name': '采妮',
 'title': '不要拿钱去试探一个女人'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181217/5c175540e810d.jpg',
 'name': '何大宝',
 'title': '这小伙子，考虑问题很专业啊'}
2019-01-09 17:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_4.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181229/5c26c798e4554.jpg',
 'name': '采妮',
 'title': '这西瓜怕是要生了啊！'}
2019-01-09 17:56:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_5.html> (referer: https://www.pengfu.com/zuijurenqi_30_4.html)
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181222/5c1d9894a2d00.jpg',
 'name': '采妮',
 'title': '墙都不扶就服你，这劈叉太厉害了！'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '我一男同事平时特别奇葩，一天我们加班很晚了，在一起开玩笑。这哥们一时疯癫，跑到公司女厕所门口大喊，出来，你们被包围了···结果，从里面战战兢兢走出来一男一女···喊话的同事也傻眼了。',
 'img': '',
 'name': '何大宝',
 'title': '叫你恶作剧，傻了吧  '}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '老婆躺我怀里问：你要是有100亿，你想做的第一件事是什么？我脱口而出：把你休了。（当时没过脑，说完感觉要坏事）老婆微怒：那第二件事呢？“把你娶回来”“为什么？”“以前娶你时办的太简单，所以要再办一次，让你嫁的风光点。”老婆一脸感动。当时，我在心里对自己说：我真是太机智了！',
 'img': '',
 'name': '何大宝',
 'title': '论应变能力的重要性  '}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181211/5c0f0459ae07c.jpg',
 'name': '粉色娘子军',
 'title': '医生的字只有医生能看懂'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181229/5c2738d00b86f.jpg',
 'name': '何大宝',
 'title': '我先说：红楼春梦，地道野战'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181226/5c22ca9baa64e.jpg',
 'name': '粉色娘子军',
 'title': '解气啊'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181227/5c2494bfe7f53.jpg',
 'name': '何大宝',
 'title': '其实钱不钱的无所谓，我就想开开劳斯莱斯'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181226/5c22d9a674491.jpg',
 'name': '采妮',
 'title': '辛苦了，老兵'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2176ee929fb.jpg',
 'name': '采妮',
 'title': '小学同学聚会，男的AA女的免费'}
2019-01-09 17:56:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_5.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181223/5c1ed4f279290.jpg',
 'name': '采妮',
 'title': '最近钱有点儿多'}
2019-01-09 17:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_6.html> (referer: https://www.pengfu.com/zuijurenqi_30_5.html)
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181220/5c1b572d90057.jpg',
 'name': '何大宝',
 'title': '妹子，你到底是嫁人还是嫁车哟'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '有一个同事，家事不顺，事业低迷。找个大师看看，大师说他家祖坟风水不好，应该动动。同事说通父母和爷爷奶奶，定好日子迁祖坟。挖开以后，在祖坟里发现四件古董，从此家业大兴！于是这家人给大师写了表扬信并送了锦旗。',
 'img': '',
 'name': '采妮',
 'title': '大师就是大师   '}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190102/5c2bf9c9eda44.jpg',
 'name': '粉色娘子军',
 'title': '年度最佳摄影：背影'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190101/5c2b2d12ba802.jpg',
 'name': '何大宝',
 'title': '都别说话，大师在用意念开车'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '我去我同事家，他说他小时候家庭经济不好，生活很艰苦。还给我看他小时候的照片。 '
            '我看到有张照片里，餐桌上有烧鸡，有白斩鸡，他们一家人表情凝重拿着鸡腿……这生活还艰苦？ '
            '我指着这张照片问：“这张照片哪一年拍的？！” 他：“哪一年忘了，我记得当时闹禽流感...”',
 'img': '',
 'name': '何大宝',
 'title': '有图不代表是真相   '}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181219/5c1a08b9be926.jpg',
 'name': '何大宝',
 'title': '像我这样会过日子的男人真的不多了'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181218/5c1837e157086.jpg',
 'name': '粉色娘子军',
 'title': '要我就买二元三斤的，买三次'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181211/5c0f69baef635.jpg',
 'name': '何大宝',
 'title': '微商的世界你懂不懂？'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190102/5c2c02bbb9a86.jpg',
 'name': '采妮',
 'title': '希望结婚之后的双方能够知道'}
2019-01-09 17:56:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_6.html>
{'content': '媳妇儿生气了怎么办？我教你一招：拿起水杯，往地上一摔，观察她的反应。如果镇住了就没事儿，要是没镇住，顺势往玻璃碴子上一跪，就摆平了。',
 'img': '',
 'name': '何大宝',
 'title': '教男捧一招，很实用的 '}
2019-01-09 17:56:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_7.html> (referer: https://www.pengfu.com/zuijurenqi_30_6.html)
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25d57d9e7aa.jpg',
 'name': '何大宝',
 'title': '学人碰瓷，把自个碰进去了吧'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181220/5c1b5467e72f2.jpg',
 'name': '何大宝',
 'title': '吓我一跳！'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '有一次旅游，在山路上，迟迟找不到厕所，时间久了，大家都憋着尿呢，这时司机灵机一动说，男的站车左边，女的站车右边，面对车解决，大家扭捏了半天，心一横准备就地解决，刚尿出来，结果司机把车开跑了！',
 'img': '',
 'name': '采妮',
 'title': '被坑得最惨的一次 '}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181214/5c135c45256bb.jpg',
 'name': '采妮',
 'title': '只能说太尼玛狠了'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181228/5c25d820ad55d.jpg',
 'name': '何大宝',
 'title': '我们村，交通发达，禁止闯红灯'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d4e67cd56.jpg',
 'name': '采妮',
 'title': '这技术不得不服啊'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22c30b98b9f.jpg',
 'name': '粉色娘子军',
 'title': '刘诗诗这个表情是什么意思啊'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181231/5c2961626eec6.jpg',
 'name': '采妮',
 'title': '偶得一幅虎啸山林图，与捧友共赏'}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '我和闺蜜逛街，对面走过来一个戴着墨镜，手拿拐杖的人。他说：美女，我一天没吃饭了，给点吧！于是，我掏出五块钱，给了他。完事之后，我就后悔了：我被骗了，他是装盲人的，不然怎么知道站在跟前的是男是女？闺蜜：知足吧，五块钱买一句美女，也很值了。你给我20，我都张不开嘴，睁眼说瞎话嘛！',
 'img': '',
 'name': '采妮',
 'title': '五块钱到底值不值？ '}
2019-01-09 17:56:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_7.html>
{'content': '昨天老婆生日，晚上她走到阳台，对着天空“啊呜”的吼了几下。我吓了一跳，问她干嘛？她说：“三十如狼了。”哇，这不是在召唤同类的异性吧？深想下去，吓得我一夜未眠。',
 'img': '',
 'name': '何大宝',
 'title': '恐慌来得太突然 '}
2019-01-09 17:56:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_8.html> (referer: https://www.pengfu.com/zuijurenqi_30_7.html)
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1dec868cd65.jpg',
 'name': '何大宝',
 'title': '这才是来看房的，真的很认真'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181221/5c1c50359d3c0.jpg',
 'name': '采妮',
 'title': '有没有愿意来我家取暖的？'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181231/5c29dd0eb0d2f.jpg',
 'name': '何大宝',
 'title': '我太高调了吧'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '看新闻看到的：单位有个老李，一直身体不好，大家就说他缺乏锻炼，于是他坚持每天围着北京二环跑步，坚持了一年多，得肺癌死了……',
 'img': '',
 'name': '何大宝',
 'title': '这叫个特么什么事！ '}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c136f94c9ae9.jpg',
 'name': '何大宝',
 'title': '这个村可能就俩人！'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190104/5c2ec06a1fd0f.jpg',
 'name': '采妮',
 'title': '假的吧，一下就破了'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c24918bb7b49.jpg',
 'name': '何大宝',
 'title': '艺术团在理工类学校里演出时学生们的反应'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d4a4ee593.jpg',
 'name': '采妮',
 'title': '妹子走路很潇洒呀'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181222/5c1d9bbca0acf.jpg',
 'name': '采妮',
 'title': '这是我亲眼看见的'}
2019-01-09 17:56:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_8.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190101/5c2b2f9a3a7f1.jpg',
 'name': '何大宝',
 'title': '朋友结婚，送他四件套'}
2019-01-09 17:56:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_9.html> (referer: https://www.pengfu.com/zuijurenqi_30_8.html)
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2b2d300ffe0.jpg',
 'name': '何大宝',
 'title': '这女的绝对练过'}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c2732417d76d.jpg',
 'name': '何大宝',
 'title': '真正的书法大师，写字都不需要用手'}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '今天上公共厕所，听见隔壁传出一阵欢快的歌声，唱法是花腔女高音：拉拉拉，拉拉拉，我是蹲坑的小行家，忘了带纸就蹲下，一边拉一边夸，今天的分量真正大，没有几秒就拉了一大把……这是在跟老娘要纸呢，给呗。',
 'img': '',
 'name': '采妮',
 'title': '公共场所还有卖唱的    '}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '我例行检查儿子的作业，作文题目《我的妈妈》。儿子写道:孩子是遗落人间的明珠，而妈妈本应是上帝派来保护孩子的天使。而我却是上帝掉落的陀螺，我妈妈则是那个喜欢抽陀螺的魔鬼……',
 'img': '',
 'name': '何大宝',
 'title': '我看这孩子平时确实是抽少了 '}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c10c43853aaf.jpg',
 'name': '何大宝',
 'title': '耍大刀耍的不错，不过容易误伤'}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328f0b794d7.jpg',
 'name': '何大宝',
 'title': '我去，岛国女人就是强啊！'}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29da098a913.jpg',
 'name': '何大宝',
 'title': '你是不是也做过这样的梦？'}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '坐一女同事的顺风车回家，路上抛锚了，同事立马下车，打开车前盖检查。我也下车问她：什么问题？她说：我哪知道，我看别的司机抛锚了都是这样做的！',
 'img': '',
 'name': '采妮',
 'title': '女司机最会装逼  '}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181218/5c18b4e77341a.jpg',
 'name': '何大宝',
 'title': '尼玛，还得跑一趟'}
2019-01-09 17:56:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_9.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c136f91769de.jpg',
 'name': '何大宝',
 'title': '真正的树妖'}
2019-01-09 17:56:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_10.html> (referer: https://www.pengfu.com/zuijurenqi_30_9.html)
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190104/5c2ec05bcff36.jpg',
 'name': '采妮',
 'title': '同事生病住院，放假我们来看望他'}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '有一次，喝多了， '
            '在饭店门口跟一只大狗子对峙，它瞪我，我也瞪它，互不相让，就这样，瞪了一个多小时，这时一位穿着保安制服的人走过来说：“你跟一只石狮子叫什么劲！”',
 'img': '',
 'name': '何大宝',
 'title': '醉酒的日常境界  '}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181231/5c29dd84b5413.jpg',
 'name': '何大宝',
 'title': '六千给少了'}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '再也没有聚的这么齐过',
 'img': 'https://image6.pengfu.com/thumb/181230/5c28820b28b58.jpg',
 'name': '何大宝',
 'title': '多少人就这么散了之后，'}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181220/5c1adb71ece22.jpg',
 'name': '粉色娘子军',
 'title': '我叫张怡宁，问我哪个张？嚣张的张'}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '昨晚找哥们出去玩，他老婆唠叨了几句，他说：“鬼什么混呢？我手机里没钱，身上也没钱，不信你搜。”他老婆真的去搜，我看到他不知何时把一卷钱用双面胶粘在了他老婆背上，他老婆毫无察觉，搜完他的身发现真的没钱就让他出去了，然后他出门时抱着他老婆亲了亲额头，顺势把她背上的钱撕下来握在手里。我在门外看得都惊呆了。',
 'img': '',
 'name': '何大宝',
 'title': '应付老婆真有一套  '}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181213/5c12156766fbf.jpg',
 'name': '何大宝',
 'title': '你哥哥真的是狠优秀！'}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181213/5c11af8f4c405.jpg',
 'name': '粉色娘子军',
 'title': '这是什么菜呢，好有创意啊'}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '今天早上，路上有一个小孩子背着书包，声音很大的愤愤的骂道：妈的，这么冷的天，全家都在睡觉。就老子一个上学\u200b……娘希皮！',
 'img': '',
 'name': '何大宝',
 'title': '晨骂   '}
2019-01-09 17:56:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_10.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190104/5c2eb5984111f.jpg',
 'name': '粉色娘子军',
 'title': '黑屏......'}
2019-01-09 17:56:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_11.html> (referer: https://www.pengfu.com/zuijurenqi_30_10.html)
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248f0e12e95.jpg',
 'name': '何大宝',
 'title': '小姐姐这个腹肌真的厉害'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181225/5c218641d0cf2.jpg',
 'name': '采妮',
 'title': '这个老爸太耿直啦，真性情呀'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '公园里，一老头手里拿着风筝线抬头看天，四周围了一群人，他们也都抬头看。其中一个路人问: '
            '“大爷，你放的是啥啊？挺高啊，我们都看不到了。” 大爷说: '
            '“别着急哈，一会就看到了。”路人们继续围观，感慨着大爷功力深厚。过了一会儿，天空中飞来一架飞机，大爷“噌”就跟着跑了，边跑边喊: '
            '“你慢点，一会儿线断了！',
 'img': '',
 'name': '何大宝',
 'title': '大爷您太忽悠人了   '}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181230/5c281b0837f72.jpg',
 'name': '采妮',
 'title': '就这么简单'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181219/5c198b1c96115.jpg',
 'name': '粉色娘子军',
 'title': '嗯。。。说的很对！'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328ec2ab416.jpg',
 'name': '何大宝',
 'title': '今年流行的彩色牛仔裤'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '公交车上比较挤，一男一女好像因为踩到脚还是碰到胸吵了起来，越吵越激烈，眼看就要有动手的举止，公交车司机大叔来了一个急刹车，然后他俩儿华丽丽的接吻了，吻上了。。。。再然后一路都安静了。。',
 'img': '',
 'name': '采妮',
 'title': '其实许多事也就是个举脚之劳  '}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab812131a1.jpg',
 'name': '采妮',
 'title': '减肥按摩要20块好像真的不贵！'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d1f29880f.jpg',
 'name': '采妮',
 'title': '豪放不羁的妹子是你喜欢的类型吗'}
2019-01-09 17:56:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_11.html>
{'content': '去夜市转悠，看到一个小包包特别小巧精致，一问价格88元，我心想还价六十差不多了，然后就跟老板比了个六。他先是一愣，然后说：“不行，六块卖不出来，起码也得再添四块，十元你拿走！”回去路上，我一直都在琢磨，我当时是不是该再还价八块的？？',
 'img': '',
 'name': '采妮',
 'title': '砍价真的是个技术活  '}
2019-01-09 17:56:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_12.html> (referer: https://www.pengfu.com/zuijurenqi_30_11.html)
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c11af7f5ea88.jpg',
 'name': '粉色娘子军',
 'title': '这是部队里的食堂'}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '在网上看到有人说，情侣之间送过鞋子的，最后都会分手。晚上和男友躺在床上聊天，我就跟他说到这个，男友听完不耐烦的说道：让你没事少上点网，一天天的净相信那些破事，睡觉睡觉。事隔几天我生日，打开男友送我的礼物，礼盒里放着一双闪亮的高跟鞋......看来下次又要编个买包包的故事了。',
 'img': '',
 'name': '采妮',
 'title': '随口一说幸福就来了 '}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181211/5c0f6996ef43d.jpg',
 'name': '何大宝',
 'title': '说好的保密发货呢？'}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328eb5560ad.jpg',
 'name': '何大宝',
 'title': '啤酒就该这样喝，这样才带劲'}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c288277c3fb5.jpg',
 'name': '何大宝',
 'title': '一脸懵逼.居然还有那么绅士的大猫？'}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '观棋不语真君子，此话一点不假。有天黄昏我在街边看下象棋，一个卖水果的，也在一边看下棋，他看岀了问题，又不便说，憋得受不了，起身推起水果车子就走，边走边吆喝:“拱卒子啦！拱卒子啦，五块钱三斤！”这都哪儿跟哪儿啊！',
 'img': '',
 'name': '何大宝',
 'title': '我见到的一位真君子  '}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181220/5c1af028b1b54.jpg',
 'name': '采妮',
 'title': '冥冥中自有天意'}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '小时候得了腮腺炎，表弟看见了，以为我嘴里有糖，我张嘴给他看，他见我嘴里什么都没有，就用手指蘸了我的口水尝尝甜不甜，，，再后来他的腮帮子也鼓起来了。我俩站在一起，活像两只小松鼠。',
 'img': '',
 'name': '何大宝',
 'title': '小吃货的最高境界  '}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181218/5c18355b3c897.jpg',
 'name': '粉色娘子军',
 'title': '我童年的幻想，破灭了'}
2019-01-09 17:56:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_12.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181212/5c106c40d81c7.jpg',
 'name': '采妮',
 'title': '地道的味道'}
2019-01-09 17:56:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_13.html> (referer: https://www.pengfu.com/zuijurenqi_30_12.html)
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2ff1f8d48bf.jpg',
 'name': '采妮',
 'title': '这个图我已循环20遍'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190104/5c2eb429b5d46.jpg',
 'name': '粉色娘子军',
 'title': '娶了她肯定很幸福的'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '老妈难得主动打来电话，聊天的过程中无意中提到邻居家换新电视了……我一听，秒懂！马上说:妈，我们也买跟他一样的，多少钱？我这就转钱！老妈笑了:就知道你对妈最好了，今天元旦家电优惠，师傅已经在安装了，让他跟你说！',
 'img': '',
 'name': '采妮',
 'title': '姜永远是老的辣  '}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '都在吐槽老娘平胸，老娘难道不想让他长大吗？老娘为了让他长大，天天木瓜牛奶醪糟汤，日日按摩运动做保养，然而并没有什么卵用！胸没大，肚子大了不少，现在小区里都在传我未婚先育了，谁他妈告诉我我男人在哪儿呢？！',
 'img': '',
 'name': '粉色娘子军',
 'title': '未婚先孕的苦恼   '}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c1354a3ba0f5.jpg',
 'name': '采妮',
 'title': '过扶梯一定要摆pose'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c1354be7fd46.jpg',
 'name': '采妮',
 'title': '亲生的和充话费送的！'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181210/5c0e3e5d6bf6c.jpg',
 'name': '何大宝',
 'title': '这个服务生一看就是过来人'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190104/5c2ec6b47a00e.jpg',
 'name': '采妮',
 'title': '调试代码的时候。。。。'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190101/5c2b3007a5b68.jpg',
 'name': '何大宝',
 'title': '全场大甩卖'}
2019-01-09 17:56:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_13.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181231/5c2961e70d4ce.jpg',
 'name': '采妮',
 'title': '老师真不是那个意思……'}
2019-01-09 17:56:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_14.html> (referer: https://www.pengfu.com/zuijurenqi_30_13.html)
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b2f068c9f.jpg',
 'name': '采妮',
 'title': '真不知道发明这样的机器人是为了啥'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '连号，说明物价要涨了。当平时爱说话的同学突然不说话，说明老师来了。当小县城出现了很多美女，说明外面扫黄。当所有人吃完饭不说话了，说明该你结帐了。当你中了五百万，不知道怎么花，说明梦该醒了。当你看到我打了这么多字，说明缘分到了，该点赞！呵呵，罗索完了。',
 'img': '',
 'name': '采妮',
 'title': '我来罗索几句   '}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181220/5c1ad9806cf1e.jpg',
 'name': '粉色娘子军',
 'title': '如果你会隐身，你最想做什么？'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181213/5c11c48e00a9c.jpg',
 'name': '采妮',
 'title': '用萝卜雕出来的'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2f958cc1393.png',
 'name': '驱逐舰hd',
 'title': '我教你放羊你干这个'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190102/5c2bfd0fa6002.jpg',
 'name': '采妮',
 'title': '敢不敢吃俺老孙一棒'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c2959a22383f.jpg',
 'name': '采妮',
 'title': '水果罐头，纯手工制作'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181222/5c1decb0d17b6.jpg',
 'name': '何大宝',
 'title': '致我们回不去的童年'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '我带上你，你带上碗，你负责哭，我负责喊，找个旅游景点，一起当老板！',
 'img': 'https://image7.pengfu.com/origin/181213/5c12158dbed74.jpg',
 'name': '何大宝',
 'title': '年底将至：'}
2019-01-09 17:56:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_14.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181210/5c0e36ebe3bbf.jpg',
 'name': '何大宝',
 'title': '这个后甩腿厉害了'}
2019-01-09 17:56:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_15.html> (referer: https://www.pengfu.com/zuijurenqi_30_14.html)
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2fee3752d27.jpg',
 'name': '采妮',
 'title': '猝不及防的搞笑'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '非常期待我看见这一幕彻底心凉了',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2fee2b51559.jpg',
 'name': '采妮',
 'title': '老公说今天晚上给我做刀削面，'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2817ed8be01.jpg',
 'name': '采妮',
 'title': '学做动画4年的朋友又出新作品喇'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181227/5c2411cca4deb.jpg',
 'name': '粉色娘子军',
 'title': '真感人啊'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1ed142af565.jpg',
 'name': '采妮',
 'title': '你们这么整蛊真是过分了啊'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '一女同事长的比较黑，穿低胸装，拍个照片发朋友圈，只给脖子以上p白了，脖子以下黑黑的，然后有人留言，妹子，你 胸 前 黑 乎 乎 '
            '的是胸毛吗？？',
 'img': '',
 'name': '采妮',
 'title': '弄巧成拙的范例  '}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181216/5c15de2c6088d.jpg',
 'name': '采妮',
 'title': '没毛病。。老铁我挺你！'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab82c5e28d.jpg',
 'name': '采妮',
 'title': '就是不一样!'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29da87c5c72.jpg',
 'name': '何大宝',
 'title': '怎么样看着有没有流嘴水...'}
2019-01-09 17:56:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_15.html>
{'content': '大师兄的日子是一天不如一天',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29d6ef38d75.jpg',
 'name': '何大宝',
 'title': '白龙马下岗后，'}
2019-01-09 17:56:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_16.html> (referer: https://www.pengfu.com/zuijurenqi_30_15.html)
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29d6aa14bdd.jpg',
 'name': '何大宝',
 'title': '你个坏蛋打死你再偷看人家'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2884e287a17.jpg',
 'name': '何大宝',
 'title': '裁判，他们作弊，他们是十二个队友'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248f3d4f598.jpg',
 'name': '何大宝',
 'title': '我靠 我 我 去'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1ecf115beb7.jpg',
 'name': '采妮',
 'title': '打架的时候姿势不能摆太久，要不然...'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181213/5c11c19b8deb4.jpg',
 'name': '采妮',
 'title': '半夜起床上厕所的我'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2ff21290ceb.jpg',
 'name': '采妮',
 'title': '有这么给力的兄弟和伴郎就是好哇！'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2ff204c0ca5.jpg',
 'name': '采妮',
 'title': '自从有了他们家里热闹多了'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190102/5c2c783b0c54c.jpg',
 'name': '何大宝',
 'title': '如此一番雪景，待本汪细细体验一番！'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c28821980e83.jpg',
 'name': '何大宝',
 'title': '铲屎的，让你玩不带我去'}
2019-01-09 17:56:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_16.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2814ec94aad.jpg',
 'name': '采妮',
 'title': '大风车而已，很简单啊，我不会'}
2019-01-09 17:56:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_17.html> (referer: https://www.pengfu.com/zuijurenqi_30_16.html)
2019-01-09 17:56:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1f4a1a6b4b5.jpg',
 'name': '何大宝',
 'title': '完美跳水'}
2019-01-09 17:56:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181221/5c1c502abe4c3.jpg',
 'name': '采妮',
 'title': '这就是北京话！'}
2019-01-09 17:56:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181219/5c1a09d632200.jpg',
 'name': '何大宝',
 'title': '有目标有计划有步骤'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181211/5c0f1cdb29f81.jpg',
 'name': '采妮',
 'title': '尴尬的接亲经历'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328c605e7ce.jpg',
 'name': '何大宝',
 'title': '我差点就信了'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190104/5c2f25b6796d3.jpg',
 'name': '何大宝',
 'title': '原来促销现场竞争这么激烈……'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c2959789b37d.jpg',
 'name': '采妮',
 'title': '好好走上去不行吗？装什么X呢'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c28852221a09.jpg',
 'name': '何大宝',
 'title': '亲姐妹和亲哥们儿的区别'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2817a0b619e.jpg',
 'name': '采妮',
 'title': '他真的不是故意的。。。'}
2019-01-09 17:56:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_17.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c217bf857bc8.jpg',
 'name': '采妮',
 'title': '练舞蹈媳妇，上床前都要先热身'}
2019-01-09 17:56:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_18.html> (referer: https://www.pengfu.com/zuijurenqi_30_17.html)
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '一哥们，公司破产了，被人追债，逢人就说自己是精神病，没人信—……后来他自己去精神病院住了一年多，出来了！逢人又说其实我没病！我没病！更没人信了！！',
 'img': '',
 'name': '采妮',
 'title': '神经病就是无人深信  '}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1adfd31eed1.jpg',
 'name': '采妮',
 'title': '闲来无事，拿出来一条命玩玩...'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1ad964667cf.jpg',
 'name': '粉色娘子军',
 'title': '见过遛狗遛猫的，遛蛇还是第一次见'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181218/5c18b41529a96.jpg',
 'name': '何大宝',
 'title': '又是虫草汤，我都胖了'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181214/5c12f2e1e816f.jpg',
 'name': '粉色娘子军',
 'title': '揣着明白装糊涂'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181230/5c281a8d9b485.jpg',
 'name': '采妮',
 'title': '兵俑界中的胖虎'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26bf347b15d.jpg',
 'name': '采妮',
 'title': '孩子你没事吧？'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b7103700a.jpg',
 'name': '采妮',
 'title': '驾驶员：我开坦克从来不看车！'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181227/5c2494174c6fd.jpg',
 'name': '何大宝',
 'title': '买个火车票跟探监一样'}
2019-01-09 17:56:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_18.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181227/5c245d6348805.jpg',
 'name': '采妮',
 'title': '这是谁家的洞府？'}
2019-01-09 17:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_19.html> (referer: https://www.pengfu.com/zuijurenqi_30_18.html)
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c240f31835ed.jpg',
 'name': '粉色娘子军',
 'title': '每当我想偷偷溜出去玩儿时…… \u200b\u200b\u200b\u200b'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1f47a953ba7.jpg',
 'name': '何大宝',
 'title': '这个谁设计的，涨工资！'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1b541c206e4.jpg',
 'name': '何大宝',
 'title': '女人养狗狗的诸多好处!'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181219/5c199204e9e47.jpg',
 'name': '采妮',
 'title': '还是油彩画的，求司机内心阴影面积'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181218/5c185965b3e3d.jpg',
 'name': '采妮',
 'title': '论标点符号的重要性'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181218/5c185581c8300.jpg',
 'name': '采妮',
 'title': '同学，今天作业很少吧'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181217/5c1727db40d3b.jpg',
 'name': '采妮',
 'title': '据说凶手在犯案后会再次回到现场'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181212/5c1065ce506ef.jpg',
 'name': '采妮',
 'title': '全自动化妆机有点野蛮哦!!'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab854b6818.jpg',
 'name': '采妮',
 'title': '姑娘你还是别进厨房了'}
2019-01-09 17:56:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_19.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab839bb3a2.jpg',
 'name': '采妮',
 'title': '小伙子你这技术太牛啦'}
2019-01-09 17:56:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_20.html> (referer: https://www.pengfu.com/zuijurenqi_30_19.html)
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2882788f04c.jpg',
 'name': '何大宝',
 'title': '摄影师你别晃了好不好我都看不清'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22d2703d4d7.jpg',
 'name': '采妮',
 'title': '哥们你是没睡醒吧'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1f4a7345846.jpg',
 'name': '何大宝',
 'title': '大妈你真不适合玩这么危险的运动'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1ca32a34269.jpg',
 'name': '何大宝',
 'title': '目标发现！俘获几个美女带回家喽！'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2ff41bab3d3.jpg',
 'name': '采妮',
 'title': '你放过我吧，下次不生这么多了'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190104/5c2f259e23f67.jpg',
 'name': '何大宝',
 'title': '超震撼的裸眼3D动图'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190101/5c2b2d057148e.jpg',
 'name': '何大宝',
 'title': '百公里耗油只需一身冷汗！'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '就可被奉为神般的存在!',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab5297ab2e.jpg',
 'name': '采妮',
 'title': '在这里，只要会写个数字，'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29d7257654e.jpg',
 'name': '何大宝',
 'title': '好害羞啊'}
2019-01-09 17:56:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_20.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29d7168fd06.jpg',
 'name': '何大宝',
 'title': '厉害了！'}
2019-01-09 17:56:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_21.html> (referer: https://www.pengfu.com/zuijurenqi_30_20.html)
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c288249d65e2.jpg',
 'name': '何大宝',
 'title': '时装秀上最正宗的猫步'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c28155daf7a7.jpg',
 'name': '采妮',
 'title': '这场面一度很尴尬。。。'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c2458dca6db8.jpg',
 'name': '采妮',
 'title': '内心独白，也没人告诉我爬山需要这样爬'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181223/5c1ed47e3a155.jpg',
 'name': '采妮',
 'title': '听说这动作男生一般做不来。。'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1ca336c9d47.jpg',
 'name': '何大宝',
 'title': '为了摘个水果....实在是太拼了'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c19fd29dabd2.jpg',
 'name': '何大宝',
 'title': '第一次见这样刷碗的，很是暴力！'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181211/5c0f1b9849764.jpg',
 'name': '采妮',
 'title': '烧不到我 看我这风骚走位'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190101/5c2abad31d142.jpg',
 'name': '采妮',
 'title': '不放过一点儿营养'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29d6c96d154.jpg',
 'name': '何大宝',
 'title': '农村的孩子谁小时候开过这种车？'}
2019-01-09 17:56:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_21.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c295e8dd8c5a.jpg',
 'name': '采妮',
 'title': '让人感觉到是忠心耿耿的帽子'}
2019-01-09 17:56:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_22.html> (referer: https://www.pengfu.com/zuijurenqi_30_21.html)
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c2959aeed60d.jpg',
 'name': '采妮',
 'title': '真的想把后面的头发拿下来'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181229/5c2738416a95b.jpg',
 'name': '何大宝',
 'title': '大哥，你这安全帽哪里买的啊？'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181228/5c25bca34f6f8.jpg',
 'name': '采妮',
 'title': '夏天是胖子们的末日'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c2491ade2106.jpg',
 'name': '何大宝',
 'title': '岳父，我会对你女儿好的，你别这样我怕'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c233c4e763f7.jpg',
 'name': '何大宝',
 'title': '小伙子，广场舞领舞需要您'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c217c5ddee22.jpg',
 'name': '采妮',
 'title': '这个爸爸绝对的人才'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1f4a3651ce0.jpg',
 'name': '何大宝',
 'title': '这都不倒是不是有点没天理了？'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c1a0488dcf04.jpg',
 'name': '何大宝',
 'title': '这是我最后一个儿子，你就别买了'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c19897f54a5c.jpg',
 'name': '粉色娘子军',
 'title': '有钱人打架都是那么任性!'}
2019-01-09 17:56:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_22.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c10660801398.jpg',
 'name': '采妮',
 'title': '大爷一脸懵逼啊，'}
2019-01-09 17:56:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_23.html> (referer: https://www.pengfu.com/zuijurenqi_30_22.html)
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328ef3d1e61.jpg',
 'name': '何大宝',
 'title': '二汪拿开你的爪子'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2ff1cab0a29.jpg',
 'name': '采妮',
 'title': '多少男人家庭地位的写照！'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190104/5c2f255877056.jpg',
 'name': '何大宝',
 'title': '这样威胁女友的家伙，通常下场都不是很好'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab862e54f3.jpg',
 'name': '采妮',
 'title': '好不容易来一趟，走一次吧'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c2959bdc6c3e.jpg',
 'name': '采妮',
 'title': '电动马达臀，就是抖的有点快'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1f4a0e71408.jpg',
 'name': '何大宝',
 'title': '傻了吧，老子会飞'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328c6e982bc.jpg',
 'name': '何大宝',
 'title': '女汉子是从小培养的'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190104/5c2f25432bf13.jpg',
 'name': '何大宝',
 'title': '如此敬业的主持人'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190102/5c2bfcb5929e0.jpg',
 'name': '采妮',
 'title': '看这妖娆的身姿'}
2019-01-09 17:56:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_23.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190102/5c2bf8716a0c3.gif',
 'name': '粉色娘子军',
 'title': '大哥的右勾拳很有气势'}
2019-01-09 17:56:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_24.html> (referer: https://www.pengfu.com/zuijurenqi_30_23.html)
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2b2d6885801.jpg',
 'name': '何大宝',
 'title': '冬天，只想这样偎在被窝里过'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190101/5c2ab4d80bb13.jpg',
 'name': '采妮',
 'title': '我说烧鸡怎么少了鸡屁股'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29da779cc09.jpg',
 'name': '何大宝',
 'title': '老子啥都不在乎，哼！'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2884adb4be6.jpg',
 'name': '何大宝',
 'title': '这桌子移动起来是方便'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '还没反应过来就结束了',
 'img': 'https://image6.pengfu.com/thumb/181230/5c28823aa4450.jpg',
 'name': '何大宝',
 'title': '史上最快的一场恋爱，'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c27327004aed.jpg',
 'name': '何大宝',
 'title': '乡下的快乐'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25d58c6bc8d.jpg',
 'name': '何大宝',
 'title': '大爷，不要轻易模仿，'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c245af81729d.jpg',
 'name': '采妮',
 'title': '这是蛤蟆还是乌龟'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181226/5c22d90f65de0.jpg',
 'name': '采妮',
 'title': '大家好，欢迎收看鲁豫有约!'}
2019-01-09 17:56:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_24.html>
{'content': '让我瞬间打消了闹婚礼的念头',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d21a541d9.jpg',
 'name': '采妮',
 'title': '看到这伴娘群，'}
2019-01-09 17:56:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_25.html> (referer: https://www.pengfu.com/zuijurenqi_30_24.html)
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181218/5c1858cb89aa4.jpg',
 'name': '采妮',
 'title': '请把黑眼圈还给我！'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181217/5c1753a080607.jpg',
 'name': '何大宝',
 'title': '好神奇！谁知道这是什么材料啊'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328f406cd2e.jpg',
 'name': '何大宝',
 'title': '起来起来！跟我一起玩！'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328c817358b.jpg',
 'name': '何大宝',
 'title': '小哥成功的把钱变没了，'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328c439cbd6.jpg',
 'name': '何大宝',
 'title': '小哥的这个头发是怎样做到的？'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c295e20228eb.jpg',
 'name': '采妮',
 'title': '原来二师兄是这样喝水的'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2815067156e.jpg',
 'name': '采妮',
 'title': '做了一辈子电工，还是放不下这把尖嘴钳'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25b300eea78.jpg',
 'name': '采妮',
 'title': '华山论剑，不不不，广场论剑！'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c24589aa52dc.jpg',
 'name': '采妮',
 'title': '没炸的发工资，炸的换人'}
2019-01-09 17:56:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_25.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c233c2649958.jpg',
 'name': '何大宝',
 'title': '...这脸变得，俺给满分！'}
2019-01-09 17:56:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_26.html> (referer: https://www.pengfu.com/zuijurenqi_30_25.html)
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '看来我注定要成为富人了',
 'img': 'https://image7.pengfu.com/thumb/181221/5c1ca306b3fea.jpg',
 'name': '何大宝',
 'title': '洪水过后捡到好几个保险柜，'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181218/5c1856d054177.jpg',
 'name': '采妮',
 'title': '想出这招的人可真是高人啊'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181212/5c105129e65c2.jpg',
 'name': '粉色娘子军',
 'title': '没错，这就是你'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328c086a4e4.jpg',
 'name': '何大宝',
 'title': '这个时候千万别扭脸，一扭就解了气'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29595d24192.jpg',
 'name': '采妮',
 'title': '见识一下真人版植物大战僵尸！'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c281541c01f7.jpg',
 'name': '采妮',
 'title': '跑步的时候一定要注意看前面'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22c2fe0c74c.jpg',
 'name': '粉色娘子军',
 'title': '伦家都酱紫了，给点反应好不好！'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181222/5c1decbf3a539.jpg',
 'name': '何大宝',
 'title': '武器系统已激活……'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1d981b1f999.jpg',
 'name': '采妮',
 'title': '这种侧滑还是第一次见，可能也就适合胖子'}
2019-01-09 17:56:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_26.html>
{'content': '，我好躲远点',
 'img': 'https://image6.pengfu.com/thumb/181219/5c19fcd170a0e.jpg',
 'name': '何大宝',
 'title': '以后你买了车一定要告诉我车牌号'}
2019-01-09 17:56:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_27.html> (referer: https://www.pengfu.com/zuijurenqi_30_26.html)
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2ff1d400330.jpg',
 'name': '采妮',
 'title': '妹子你凭本事开的电梯门'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab4f611542.jpg',
 'name': '采妮',
 'title': '养一只监督小孩做作业的狗'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29da247ecf1.jpg',
 'name': '何大宝',
 'title': '宿敌'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29da16ebcf7.jpg',
 'name': '何大宝',
 'title': '传说的轻功水上漂'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '大家是否都需要一个风骚的摄影师',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29d9fcd54b1.jpg',
 'name': '何大宝',
 'title': '拍婚纱时，'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c295e47064cd.jpg',
 'name': '采妮',
 'title': '只要心中有曲，哪里都是舞台'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29596becd18.jpg',
 'name': '采妮',
 'title': '看到这个我就笑了'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2881f7839ce.jpg',
 'name': '何大宝',
 'title': '天才总是与众不同的'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1ca361ece85.jpg',
 'name': '何大宝',
 'title': '这个陪练很专业哦！'}
2019-01-09 17:56:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_27.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1b544e49e3b.jpg',
 'name': '何大宝',
 'title': '嘴贱的遇到手贱的，还是后者更胜一筹!'}
2019-01-09 17:56:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_28.html> (referer: https://www.pengfu.com/zuijurenqi_30_27.html)
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181219/5c1989713ba5f.jpg',
 'name': '粉色娘子军',
 'title': '什么东西是，腐蚀性好强...'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181218/5c18b077ba09f.jpg',
 'name': '何大宝',
 'title': '朋友就是在你困惑的时候，推你一把的那个人'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c10662c8771f.jpg',
 'name': '采妮',
 'title': '分享一只别人家的喵'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2ff21f11773.jpg',
 'name': '采妮',
 'title': '得罪女人的下场很惨...'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2ff1ec154b2.jpg',
 'name': '采妮',
 'title': '自从贴了这个，超车的少了'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190101/5c2b2bc061cec.jpg',
 'name': '何大宝',
 'title': '让你不回家，我背你好了吧！'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25b6e3b22db.jpg',
 'name': '采妮',
 'title': '喝个酸奶就不要摆poss了'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181228/5c25641a46eaf.gif',
 'name': '粉色娘子军',
 'title': '只能说你家装修材料质量不行'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c240f425d7da.jpg',
 'name': '粉色娘子军',
 'title': '这么妖娆的骚年，已是不多见了'}
2019-01-09 17:56:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_28.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c233c3f3bd8f.jpg',
 'name': '何大宝',
 'title': '再狡猾的狐狸也有想不开的时候'}
2019-01-09 17:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_29.html> (referer: https://www.pengfu.com/zuijurenqi_30_28.html)
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '在学校门口代充电宝能赚多少钱',
 'img': 'https://image7.pengfu.com/origin/181217/5c1711d9cff7d.jpg',
 'name': '粉色娘子军',
 'title': '你永远不知道'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181212/5c106d8a045cf.jpg',
 'name': '采妮',
 'title': '这说的，好像没什么不对！'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181210/5c0e3b6857044.jpg',
 'name': '何大宝',
 'title': '你等着我 我这就下去救你'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181230/5c2887d553f7e.jpg',
 'name': '何大宝',
 'title': '天真冷……'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181228/5c25670088f41.jpg',
 'name': '粉色娘子军',
 'title': '想花你钱却不想被你睡'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181225/5c21717c21a15.jpg',
 'name': '粉色娘子军',
 'title': '让你逗我，让你尝尝童子尿！'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1f47761fed4.jpg',
 'name': '何大宝',
 'title': '你要的拉面很快就来了客官'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181221/5c1ca01061f49.jpg',
 'name': '何大宝',
 'title': '龙卷风：小样来吧，我送你上天！'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181212/5c106624405bb.jpg',
 'name': '采妮',
 'title': '这枪的后坐力有点大啊！'}
2019-01-09 17:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_29.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181211/5c0f65937f01a.jpg',
 'name': '何大宝',
 'title': '这是什么情况？加完油不想给钱吗'}
2019-01-09 17:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_30.html> (referer: https://www.pengfu.com/zuijurenqi_30_29.html)
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190102/5c2bfcd066142.jpg',
 'name': '采妮',
 'title': '吃我一拳'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab8469e850.jpg',
 'name': '采妮',
 'title': '都冲一小时了，该换别的车了！'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29da5e728f1.jpg',
 'name': '何大宝',
 'title': '别人的女朋友VS你的女朋友'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c233c5fe1061.jpg',
 'name': '何大宝',
 'title': '这实力可以夺冠的，只怪裤子太松了'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1adfe0d184a.jpg',
 'name': '采妮',
 'title': '爬起来一看，沙坑里两个洞！'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c1991b1d92e4.jpg',
 'name': '采妮',
 'title': '身为老师的我自己也没有准备好呢～'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181217/5c17539a094f5.jpg',
 'name': '何大宝',
 'title': '好强的平衡能力'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2feea2ccfc2.jpg',
 'name': '采妮',
 'title': '我看看还有谁能做到'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29da6d97d5e.jpg',
 'name': '何大宝',
 'title': '坑人不成，懵逼了吧！'}
2019-01-09 17:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_30.html>
{'content': '全班都快被你带跑偏了',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29da4bdc6c6.jpg',
 'name': '何大宝',
 'title': '你这一个立定练了一下午，'}
2019-01-09 17:56:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_31.html> (referer: https://www.pengfu.com/zuijurenqi_30_30.html)
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c288278ef466.jpg',
 'name': '何大宝',
 'title': '作为一名男生，竟然穿着婚纱'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1d95e961ef9.jpg',
 'name': '采妮',
 'title': '保护环境，人人有责'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181217/5c1710b3d442d.jpg',
 'name': '粉色娘子军',
 'title': '应该是贝多芬养的猫吧'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26beb6c59d0.jpg',
 'name': '采妮',
 'title': '放开我，我不要做你的舞伴'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '最近卖起了刀削面',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1c3b6625fdb.jpg',
 'name': '粉色娘子军',
 'title': '奥特曼彻底被人类征服了，'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1aedf9e584f.jpg',
 'name': '采妮',
 'title': '还好哥哥眼疾手快的接住了'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26bf25ab07c.jpg',
 'name': '采妮',
 'title': '自作自受'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2171541de5b.jpg',
 'name': '粉色娘子军',
 'title': '胃口太大，吓坏旁人'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1ae008869c4.jpg',
 'name': '采妮',
 'title': '酒鬼的尬舞'}
2019-01-09 17:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_31.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181216/5c162b20448bb.jpg',
 'name': '秦不安',
 'title': '九珠'}
2019-01-09 17:56:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_32.html> (referer: https://www.pengfu.com/zuijurenqi_30_31.html)
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2ff1bf564d9.jpg',
 'name': '采妮',
 'title': '丐帮大联欢'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c2959da9fc07.jpg',
 'name': '采妮',
 'title': '在浮桥上开车是什么感觉呢'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d4f09fa04.jpg',
 'name': '采妮',
 'title': '小兔子在嘀咕什么呢？'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1c3a4c7298e.jpg',
 'name': '粉色娘子军',
 'title': '据说这种高跟鞋穿上特别难受'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328f2e30919.jpg',
 'name': '何大宝',
 'title': '这俩人太会玩'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190104/5c2f25a8d22c9.jpg',
 'name': '何大宝',
 'title': '万万没想到'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab4e35b734.jpg',
 'name': '采妮',
 'title': '泡妞秘籍，一般人我不告诉他'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '狗子再好也不能拿来当男朋友',
 'img': 'https://image6.pengfu.com/thumb/181231/5c2959946850d.jpg',
 'name': '采妮',
 'title': '妹子长点心吧，'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2885148dba6.jpg',
 'name': '何大宝',
 'title': '打饭手不抖了，只不过肉少青菜多了'}
2019-01-09 17:56:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_32.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26bee3538ea.jpg',
 'name': '采妮',
 'title': '妹子你入戏太深了'}
2019-01-09 17:56:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_33.html> (referer: https://www.pengfu.com/zuijurenqi_30_32.html)
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1d982851a35.jpg',
 'name': '采妮',
 'title': '妹子冲我来，我一点也不介意'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/181212/5c10c952344ff.jpg',
 'name': '何大宝',
 'title': '老婆带回来的烤地瓜 \u200b\u200b\u200b'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328bece600c.jpg',
 'name': '何大宝',
 'title': '我想知道你的脖子是不是就是这样搞坏的？'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2817920cc18.jpg',
 'name': '采妮',
 'title': '班级荣誉就靠你了！'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328c3434e1d.jpg',
 'name': '何大宝',
 'title': '真的好饿，还是让我先吃一点吧'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190107/5c328c25059d7.jpg',
 'name': '何大宝',
 'title': '既已背影得天下，何必回头乱芳华'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181222/5c1d956e8b32e.jpg',
 'name': '采妮',
 'title': '你们说我需要男朋友吗？'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2ab56ff165f.jpg',
 'name': '采妮',
 'title': '骚起来小心闪了你的腰~'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29d70769616.jpg',
 'name': '何大宝',
 'title': '手撕电话薄膜'}
2019-01-09 17:56:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_33.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2884ba303ab.jpg',
 'name': '何大宝',
 'title': '我有特殊蛋碎技巧！'}
2019-01-09 17:56:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_34.html> (referer: https://www.pengfu.com/zuijurenqi_30_33.html)
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22d2472bb79.jpg',
 'name': '采妮',
 'title': '假装照镜子……你是谁！'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c295e7e26f55.jpg',
 'name': '采妮',
 'title': '动画诚不欺我'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '你可以尝试半夜两点打电话给你老师，说：“老师，睡了么？”他说：“睡了，什么事？”这时你用最大的力气吼出来：“老子他妈的还在写作业！”然后趁他没反应过来，果断挂掉！…',
 'img': '',
 'name': '紫由',
 'title': '写作业'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2884fe003a8.jpg',
 'name': '何大宝',
 'title': '这超市鱼的悟性很高'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328c50cbe7e.jpg',
 'name': '何大宝',
 'title': '身高不够，只能这样做'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29da337dba7.jpg',
 'name': '何大宝',
 'title': '小姐姐长点心吧！每天都要累死我了'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c28154f567b4.jpg',
 'name': '采妮',
 'title': '美女最新坐骑'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181222/5c1d9b5f43d9a.jpg',
 'name': '采妮',
 'title': '好大的芝麻球啊，'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26bed4db364.jpg',
 'name': '采妮',
 'title': '这个双十一终于不用过光棍节了!'}
2019-01-09 17:56:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_34.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181222/5c1deeda6ee2e.jpg',
 'name': '何大宝',
 'title': '吃货求食的路总是充满坎坷的！'}
2019-01-09 17:56:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_35.html> (referer: https://www.pengfu.com/zuijurenqi_30_34.html)
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190102/5c2bfd01b99d7.jpg',
 'name': '采妮',
 'title': '和我那败家媳妇，一样一样滴'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29d6afc1f00.jpg',
 'name': '何大宝',
 'title': '社会猪'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c2959cae6e17.jpg',
 'name': '采妮',
 'title': '这个简单，趁树不注意的时候就可以了'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2817fb8adeb.jpg',
 'name': '采妮',
 'title': '这力气，这平衡能力!'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1def1ac71fb.jpg',
 'name': '何大宝',
 'title': '我让你开车玩手机，'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c19922364c79.jpg',
 'name': '采妮',
 'title': '有了二胎之后看来老大的生活不好过啊'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c10663f1909e.jpg',
 'name': '采妮',
 'title': '你这是要把老公憋死啊'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328f1ec39e1.jpg',
 'name': '何大宝',
 'title': '懒的最高境界！'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2817e039e78.jpg',
 'name': '采妮',
 'title': '要不是菜刀在眼前放着还真有点镇不住场面'}
2019-01-09 17:56:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_35.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c281534020e4.jpg',
 'name': '采妮',
 'title': '象哥，能不能正经点'}
2019-01-09 17:56:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_36.html> (referer: https://www.pengfu.com/zuijurenqi_30_35.html)
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1f4796a564a.jpg',
 'name': '何大宝',
 'title': '这就是闺蜜，关键的时候也不拉一把'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '但是帅哥是怎么定义的呢？',
 'img': 'https://image6.pengfu.com/thumb/190102/5c2bfce4eea2c.jpg',
 'name': '采妮',
 'title': '我知道什么叫做美女，'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c295e70c6b5d.jpg',
 'name': '采妮',
 'title': '看我的气功波'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c249183c5fb2.jpg',
 'name': '何大宝',
 'title': '第一次送女朋友礼物'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328ee761ded.jpg',
 'name': '何大宝',
 'title': '今天这戏有亮点'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2fee8739f37.jpg',
 'name': '采妮',
 'title': '本以为妹子气势如虹，没想到一泻千里！'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2ff1df9651f.jpg',
 'name': '采妮',
 'title': '我到底做错什么了？亲爱的怎么不理我了'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b701745ad.jpg',
 'name': '采妮',
 'title': '和雪崩赛跑的滑雪达人'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c295e3a69ec8.jpg',
 'name': '采妮',
 'title': '握我！只能握我！'}
2019-01-09 17:56:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_36.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b6eb46039.jpg',
 'name': '采妮',
 'title': '姑娘，这是咋滴了'}
2019-01-09 17:56:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_37.html> (referer: https://www.pengfu.com/zuijurenqi_30_36.html)
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2176cfd1e70.jpg',
 'name': '采妮',
 'title': '室友看了《叶问》后'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1ece7f26603.jpg',
 'name': '采妮',
 'title': '这字体太美了，我真的被迷住了'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2884ef6a9b9.jpg',
 'name': '何大宝',
 'title': '这样跳水的方式应该肚皮很疼吧'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c288225cf826.jpg',
 'name': '何大宝',
 'title': '这身行头应该不少值钱'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181219/5c1997982eb03.jpg',
 'name': '采妮',
 'title': '妹子，偷东西是不好的'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2817aeb7a42.jpg',
 'name': '采妮',
 'title': '就你这反应速度还是别学拳击了'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d1e6af203.jpg',
 'name': '采妮',
 'title': '今天叫了个专车，瞬间感觉好幸福'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181219/5c199233aeeeb.jpg',
 'name': '采妮',
 'title': '骚年你真会玩啊'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2fee94aa80d.jpg',
 'name': '采妮',
 'title': '现在捡垃圾都这么时尚潮流吗？'}
2019-01-09 17:56:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_37.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181212/5c106145aba88.jpg',
 'name': '采妮',
 'title': '看了好几遍才找到亮点！'}
2019-01-09 17:56:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_38.html> (referer: https://www.pengfu.com/zuijurenqi_30_37.html)
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181213/5c11c4b165723.jpg',
 'name': '采妮',
 'title': '教你一招'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c295e62aacbf.jpg',
 'name': '采妮',
 'title': '二胎果然好啊！'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c245b10cff52.jpg',
 'name': '采妮',
 'title': '女友过生日, 刚进行到一半就提出跟我分手'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1def12c141e.jpg',
 'name': '何大宝',
 'title': '别开枪！别开枪！我自己过来！'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c10616388cc7.jpg',
 'name': '采妮',
 'title': '狗狗的球技'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328edbb0b78.jpg',
 'name': '何大宝',
 'title': '这艘友谊的小船说翻就翻'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c10613a0a53b.jpg',
 'name': '采妮',
 'title': '一车妹子正向你袭来'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2817b8c2a55.jpg',
 'name': '采妮',
 'title': '妹子，你这水准就敢穿黑带了'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c295ea23dbeb.jpg',
 'name': '采妮',
 'title': '这水龙头也太声东击西了吧！'}
2019-01-09 17:56:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_38.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c28178494718.jpg',
 'name': '采妮',
 'title': '看!灰鸡!'}
2019-01-09 17:56:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_39.html> (referer: https://www.pengfu.com/zuijurenqi_30_38.html)
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '你怎么和嫂子喝上了啊',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26bef915973.jpg',
 'name': '采妮',
 'title': '你媳妇喊你回家吃饭呢，'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1aee094af7d.jpg',
 'name': '采妮',
 'title': '我是该擦还是买张膜贴上去'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190102/5c2bfcf35bd1f.jpg',
 'name': '采妮',
 'title': '腿短的悲哀！'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29d73634807.jpg',
 'name': '何大宝',
 'title': '车辆追尾是多么严重'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c295e2d3c05a.jpg',
 'name': '采妮',
 'title': '是时候表演真正的技术了'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c288507bf7f7.jpg',
 'name': '何大宝',
 'title': '受伤害的，明明是鞋子和帽子'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190107/5c328bfa0e861.jpg',
 'name': '何大宝',
 'title': '你到底有多钟爱榴莲？'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22d49ba4ba6.jpg',
 'name': '采妮',
 'title': '妹子真的好高啊'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c28828310a2d.jpg',
 'name': '何大宝',
 'title': '摇了那么久，却没有摇到得原因'}
2019-01-09 17:56:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_39.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190102/5c2bfcc261022.jpg',
 'name': '采妮',
 'title': '完美后空翻，完美摔进医院'}
2019-01-09 17:56:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_40.html> (referer: https://www.pengfu.com/zuijurenqi_30_39.html)
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190102/5c2bfca9d5d61.jpg',
 'name': '采妮',
 'title': '新娘：不想结婚是不可能的，跑不了的'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181231/5c29d74da7e1b.jpg',
 'name': '何大宝',
 'title': '还没结婚，都给你弄砸了'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c2735883c5f8.jpg',
 'name': '何大宝',
 'title': '这个傻姑娘，为什么要去抢这个男人'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26c2b0a9dc8.jpg',
 'name': '采妮',
 'title': '太刺激了，背上的皮肯定都没了!'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c29d6da106d5.jpg',
 'name': '何大宝',
 'title': '洗衣机：我要起飞了'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2172aaa31ba.jpg',
 'name': '粉色娘子军',
 'title': '这是一段说不出道不明的爱情故事'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1ed14f7cf55.jpg',
 'name': '采妮',
 'title': '治愈系清纯妹子！'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c2735bd55cc2.jpg',
 'name': '何大宝',
 'title': '演给他看'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '买了一堆水桶自制“滚筒车”',
 'img': 'https://image7.pengfu.com/thumb/181223/5c1f4a8a7bb77.jpg',
 'name': '何大宝',
 'title': '幼儿园给孩子买不起玩具车，'}
2019-01-09 17:56:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_40.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26bea894363.jpg',
 'name': '采妮',
 'title': '天气太热，连方向盘都烫人'}
2019-01-09 17:56:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_41.html> (referer: https://www.pengfu.com/zuijurenqi_30_40.html)
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248ee5067ef.jpg',
 'name': '何大宝',
 'title': '一根棒棒糖能领走'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190105/5c2fee7853a46.jpg',
 'name': '采妮',
 'title': '可以看出那根钢丝真的尽力了'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26c2c00b2c8.jpg',
 'name': '采妮',
 'title': '还以为是啥植物生长呢'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b322af867.jpg',
 'name': '采妮',
 'title': '求求你了爸爸，不要去上班'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25b33d339cd.jpg',
 'name': '采妮',
 'title': '要娶媳妇了，不买个豪车怎么可以'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181220/5c1ae0242b6ee.jpg',
 'name': '采妮',
 'title': '这个杀手不太冷，只是有点蠢'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c1991d2b9b38.jpg',
 'name': '采妮',
 'title': '定点倒立，'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2817d202785.jpg',
 'name': '采妮',
 'title': '这姑娘真不知好歹'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c2735b51e817.jpg',
 'name': '何大宝',
 'title': '看到蛋糕的那一刻，瞬间傻眼了'}
2019-01-09 17:56:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_41.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c217bdd5deec.jpg',
 'name': '采妮',
 'title': '不知是哪一位仙子'}
2019-01-09 17:56:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_42.html> (referer: https://www.pengfu.com/zuijurenqi_30_41.html)
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26c2dd08730.jpg',
 'name': '采妮',
 'title': '快跑...我老公回来了'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '我还得恢复成猪的模样！',
 'img': 'https://image6.pengfu.com/thumb/181227/5c24916fde8d3.jpg',
 'name': '何大宝',
 'title': '被生活狠狠的摔在地上，'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c241112d3316.jpg',
 'name': '粉色娘子军',
 'title': '到战场上发现只剩司机一人了'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181221/5c1c9ff41eaba.jpg',
 'name': '何大宝',
 'title': '好暖心的一幕'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2fee6c1330b.jpg',
 'name': '采妮',
 'title': '不要惹我，我怒了连我自己都要活埋'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190104/5c2ec04d60383.jpg',
 'name': '采妮',
 'title': '能分出谁是奶奶谁是孙女吗？'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c2735c780c44.jpg',
 'name': '何大宝',
 'title': '不到最后你绝对猜不到这是啥'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190104/5c2ebfde248ef.jpg',
 'name': '采妮',
 'title': '饭店里没有勺子怎么办呢？'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c2458cf42411.jpg',
 'name': '采妮',
 'title': '就因为你，吓跑了所有人'}
2019-01-09 17:56:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_42.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22d4c9c9570.jpg',
 'name': '采妮',
 'title': '初次见面，如何令人永远难忘!'}
2019-01-09 17:56:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_43.html> (referer: https://www.pengfu.com/zuijurenqi_30_42.html)
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181216/5c15dcbb66431.jpg',
 'name': '采妮',
 'title': '男孩亲了还嫌弃女孩子'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c245b3f72050.jpg',
 'name': '采妮',
 'title': '大爷为了碰瓷也是拼了啊'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181218/5c18364542cfe.jpg',
 'name': '粉色娘子军',
 'title': '牵着他的小宠物去赶集'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181231/5c295e544435b.jpg',
 'name': '采妮',
 'title': '转发了支付宝中国锦鲤的你'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2814e14f676.jpg',
 'name': '采妮',
 'title': '猫：等老子一会缓过来的！'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1ca2baaf8a5.jpg',
 'name': '何大宝',
 'title': '嗨，美女过来一起吃嘛'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1c44b161cfe.jpg',
 'name': '采妮',
 'title': '到底谁是亲生的'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/181214/5c13be3ab09c5.jpg',
 'name': '秦不安',
 'title': '这小姐姐真好看'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26bec5307c7.jpg',
 'name': '采妮',
 'title': '果然家里没有女人不行啊。'}
2019-01-09 17:56:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_43.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c13548d38f3b.jpg',
 'name': '采妮',
 'title': '一下打到两个人，真的是太厉害了'}
2019-01-09 17:56:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_44.html> (referer: https://www.pengfu.com/zuijurenqi_30_43.html)
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181218/5c1856e98f6f9.jpg',
 'name': '采妮',
 'title': '以后再也不做低头族了'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2176a6b0298.jpg',
 'name': '采妮',
 'title': '这样锻炼身体真省钱'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1eceee9405d.jpg',
 'name': '采妮',
 'title': '沾到嘴唇上的是啥呀？'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2176b499e23.jpg',
 'name': '采妮',
 'title': '我掉钱了，不对是我掉手机了！'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c273275561da.jpg',
 'name': '何大宝',
 'title': '你完了，店长这人贼小气的'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25b36d02b82.jpg',
 'name': '采妮',
 'title': '杀马特已经出现了'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248ed8bd16b.jpg',
 'name': '何大宝',
 'title': '后面的小哥一定用了原力！'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c245881a6735.jpg',
 'name': '采妮',
 'title': '不愿意接受也没有办法，'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d2010784e.jpg',
 'name': '采妮',
 'title': '有人能看出来这写的什么字吗'}
2019-01-09 17:56:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_44.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c13547cb4dd8.jpg',
 'name': '采妮',
 'title': '我家的金毛失恋后就成这个样子了'}
2019-01-09 17:56:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_45.html> (referer: https://www.pengfu.com/zuijurenqi_30_44.html)
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190104/5c2ec70d2bc91.jpg',
 'name': '采妮',
 'title': '这广告也没谁了'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190101/5c2ab505330d7.jpg',
 'name': '采妮',
 'title': '旁边的那位姑娘表示内心受到了一万点伤害'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181226/5c22d4d4a666c.jpg',
 'name': '采妮',
 'title': '鳄鱼：你娘亲的突然踩我一脚干嘛'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181220/5c1aee215d143.jpg',
 'name': '采妮',
 'title': '方围一公里不留活口'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2fee5e7f51b.jpg',
 'name': '采妮',
 'title': '姑娘悠着点'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c2735945c7fd.jpg',
 'name': '何大宝',
 'title': '烫并快乐着，我突然也想吃番薯了……'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c273260eec6a.jpg',
 'name': '何大宝',
 'title': '有这么麻烦吗？来看我的！'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c2491327d983.jpg',
 'name': '何大宝',
 'title': '这是我在足球场上，受过最重的伤'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c245ae099bd4.jpg',
 'name': '采妮',
 'title': '这贱贱的小眼神'}
2019-01-09 17:56:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_45.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c27337951dc6.jpg',
 'name': '何大宝',
 'title': '毫无违和感的眼神，我也是醉了'}
2019-01-09 17:56:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_46.html> (referer: https://www.pengfu.com/zuijurenqi_30_45.html)
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25d597b6ee7.jpg',
 'name': '何大宝',
 'title': '这面具毫无违和感'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181225/5c2176995113c.jpg',
 'name': '采妮',
 'title': '洁癖'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1ece9c9af17.jpg',
 'name': '采妮',
 'title': '我说他偷吃屎了，他就用这个表情对我'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1d980a12a6d.jpg',
 'name': '采妮',
 'title': '听到零食包装袋被撕开的声音时的我'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c1354da0d757.jpg',
 'name': '采妮',
 'title': '过马路的时候不要翻护栏'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190105/5c2fee4584030.jpg',
 'name': '采妮',
 'title': '有这样的二货女友伤不起啊'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25d5a6ada2b.jpg',
 'name': '何大宝',
 'title': '好机智的舞伴'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1deece4c845.jpg',
 'name': '何大宝',
 'title': '三个戏精'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181219/5c19fd6492f29.jpg',
 'name': '何大宝',
 'title': '旅行达人 , 任性'}
2019-01-09 17:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_46.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181218/5c18b00f18ba6.jpg',
 'name': '何大宝',
 'title': '如果换做是你，肯定比他还激动...'}
2019-01-09 17:56:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_47.html> (referer: https://www.pengfu.com/zuijurenqi_30_46.html)
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26c2ce50c2d.jpg',
 'name': '采妮',
 'title': '从某宝上网购衣服回来的你，很真实'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25d558c9738.jpg',
 'name': '何大宝',
 'title': '你的舞蹈动作真优美'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22d22767bd5.jpg',
 'name': '采妮',
 'title': '这个动作 哪个男士可以挑战'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181214/5c136fa3ad65f.jpg',
 'name': '何大宝',
 'title': '别看我是个裁判，发起火来我自己都怕自己'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181230/5c2817c5355f6.jpg',
 'name': '采妮',
 'title': '泼水节'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c26bf078f26f.jpg',
 'name': '采妮',
 'title': '有些事情是天生注定的，你永远也模仿不来'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1def278f49c.jpg',
 'name': '何大宝',
 'title': '你麻麻喊你穿秋裤没！'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181222/5c1deef478037.jpg',
 'name': '何大宝',
 'title': '有这么一只狗狗，可以不要老婆了……'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181230/5c2814f90ad71.jpg',
 'name': '采妮',
 'title': '冰死喵了'}
2019-01-09 17:56:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_47.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181229/5c26c29667330.jpg',
 'name': '采妮',
 'title': '熊孩子真讨厌'}
2019-01-09 17:56:54 [scrapy.extensions.logstats] INFO: Crawled 47 pages (at 47 pages/min), scraped 470 items (at 470 items/min)
2019-01-09 17:56:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_48.html> (referer: https://www.pengfu.com/zuijurenqi_30_47.html)
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181228/5c25b32fa52cf.jpg',
 'name': '采妮',
 'title': '做大圣就是要优雅！'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1c4a764c2d7.jpg',
 'name': '采妮',
 'title': '没吃过猪肉也见过猪玩滑板吧？'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190101/5c2b2b5fc0daf.jpg',
 'name': '何大宝',
 'title': '厉害了，小哥'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b360620e4.jpg',
 'name': '采妮',
 'title': '如此恶作剧真不怕被打死吗'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22c3e169d0f.jpg',
 'name': '粉色娘子军',
 'title': '我的野蛮女友！'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2172b8e8aec.jpg',
 'name': '粉色娘子军',
 'title': '到底有多少身衣服'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181223/5c1f478704db9.jpg',
 'name': '何大宝',
 'title': '最后一点你是故意的还是真是笨？'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181225/5c217689b9852.jpg',
 'name': '采妮',
 'title': '赔我节操，还我纯真！'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c22d50b74b54.jpg',
 'name': '采妮',
 'title': '闪开，本喵可是正经喵'}
2019-01-09 17:56:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_48.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181225/5c2171d145908.jpg',
 'name': '粉色娘子军',
 'title': '这孩子好像傻了吧'}
2019-01-09 17:56:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_49.html> (referer: https://www.pengfu.com/zuijurenqi_30_48.html)
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181217/5c175323e2b83.jpg',
 'name': '何大宝',
 'title': '赵丽颖也没那么难画嘛，一直画圈就完成了'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181228/5c25b6b0bca0b.jpg',
 'name': '采妮',
 'title': '你在吃啥'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248ef4cf58f.jpg',
 'name': '何大宝',
 'title': '新娘子：撞到谁，我就嫁给谁！'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1c4a8f8674b.jpg',
 'name': '采妮',
 'title': '骑自行车也就算了，你还不看路'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181212/5c1066135e4a0.jpg',
 'name': '采妮',
 'title': '戴个帽子可以防晒哦'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181229/5c2735a25ace1.jpg',
 'name': '何大宝',
 'title': '你不会骑摩托车居然还带人，危险啊'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '成功几率会不会高出很多',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248f3081575.jpg',
 'name': '何大宝',
 'title': '用这么大的一束花求婚的话，'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181227/5c24588eb8bec.jpg',
 'name': '采妮',
 'title': '拿开你的手！'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181221/5c1c4a6a80ef9.jpg',
 'name': '采妮',
 'title': '喂朋友，你能不能敬点业？'}
2019-01-09 17:56:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_49.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181218/5c18b22945c13.jpg',
 'name': '何大宝',
 'title': '这什么老板啊，工作一天都累成这样了'}
2019-01-09 17:56:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_30_50.html> (referer: https://www.pengfu.com/zuijurenqi_30_49.html)
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181218/5c18553c7351e.jpg',
 'name': '采妮',
 'title': '上古留下来的魔毯，大家猜猜多少年了'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/181216/5c15dcacba476.jpg',
 'name': '采妮',
 'title': '包顿饺子还有三个监工'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181213/5c11c1688a72c.jpg',
 'name': '采妮',
 'title': '街头发现一头牛在吃隔壁的草'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181212/5c1061575ac9d.jpg',
 'name': '采妮',
 'title': '危机意识要从小灌输'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181226/5c233c88d7c63.jpg',
 'name': '何大宝',
 'title': '孩子还太小，冲我来吧'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1dec950cad6.jpg',
 'name': '何大宝',
 'title': '兄弟我顶不住了，快来帮我呀！'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181222/5c1d98719c13b.jpg',
 'name': '采妮',
 'title': '孩子正在结印，没看错应该是螺旋丸'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181219/5c1991f3ec2e3.jpg',
 'name': '采妮',
 'title': '多行不义必自毙啊，不要总想着陷害别人'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181214/5c1354f36ec45.jpg',
 'name': '采妮',
 'title': '切菜机器人'}
2019-01-09 17:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_30_50.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/181227/5c248f018185b.jpg',
 'name': '何大宝',
 'title': '新娘口味有点重'}
2019-01-09 17:56:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-09 17:56:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 20540,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 371286,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 9, 9, 56, 57, 689540),
 'item_scraped_count': 500,
 'log_count/DEBUG': 551,
 'log_count/INFO': 8,
 'request_depth_max': 49,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2019, 1, 9, 9, 55, 54, 172336)}
2019-01-09 17:56:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:10:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:10:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:10:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:10:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:10:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:10:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:10:20 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:10:20 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:10:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:10:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:10:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:10:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e0706e644.jpg',
 'name': '采妮',
 'title': '大爷这技术溜啊'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e0b3b80ed.jpg',
 'name': '采妮',
 'title': '干这行要眼疾手快'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '他横由他横，明月照大江',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3faaf4d0.jpg',
 'name': '采妮',
 'title': '他强任他强，清风抚山岗。'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e391719fa.jpg',
 'name': '采妮',
 'title': '好心疼这车橘子，就这样完了！'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3aca3f45.jpg',
 'name': '采妮',
 'title': '孩子，亏你还能尿得出来…'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e08dc0b0f.jpg',
 'name': '采妮',
 'title': '这个就不用每天早上洗头了'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '受到了100000点暴击。。。',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3d1bfe7c.jpg',
 'name': '采妮',
 'title': '想找喵星人玩的狗狗，'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3ff89789.jpg',
 'name': '采妮',
 'title': '竹子君和牵牛花'}
2019-01-10 11:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_2.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e03ecc042.jpg',
 'name': '采妮',
 'title': '猫咪正在试探二狗子的最后底线'}
2019-01-10 11:10:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_3.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e4068c258.jpg',
 'name': '采妮',
 'title': '根本停不下来'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e00f57660.jpg',
 'name': '采妮',
 'title': '横店公交的日常'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e426e3906.jpg',
 'name': '采妮',
 'title': '这个大哥烦人烦人的'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '一个人在家，洗完澡后穿条内裤坐电脑前一边上网一边吃核桃，',
 'img': '',
 'name': '紫由',
 'title': '夹核桃'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '父亲叫儿子打酒，儿子问爸爸：“瓶子里不是还有吗？”爸爸摇摇头说：“太少了。”几分钟后，儿子提着瓶子回来了。父亲接过酒瓶一看，楞住了……原来酒瓶里装着大半瓶石子。儿子得意洋洋地说：“爸爸，您喝吧，乌鸦就是这样喝水的。”',
 'img': '',
 'name': '紫由',
 'title': '乌鸦喝水'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '儿子“妈妈，母亲是什么意思?”\u3000\u3000妈妈“‘母亲’就是妈妈的另一种叫法。”\u3000\u3000'
            '爸爸在一旁问：\u3000“那爸爸的另一种叫法呢?”\u3000\u3000儿子大声地说：“公亲。”',
 'img': '',
 'name': '紫由',
 'title': '在逗我吗？'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '一天上班无聊中在玩手机，突然看到老板过来了，我就匆忙把手机收起来，一不小心把手机掉地上了，我还慌乱中，老板弯腰帮我把手机捡了起来，然后跟我说了句我这辈子都能记住的话。 '
            '他说：没事，你玩你的，只要你把事情做好了，我不会说你，没必要做样子给我看，我也不喜欢别人只做样子；今天我是你老板，说不定哪天我破产，你发达了，我就要给你打工呢？做人实实在在就好……。结果第二天我因为穿运动鞋被开除了！',
 'img': '',
 'name': '紫由',
 'title': '因为穿运动鞋被开除了！'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '有一位小伙子，特吝啬，相亲了许多姑娘都没有成，父母很着急。这天，又委托媒人领着他去一位姑娘家相亲。相亲后，小伙子没有表态，媒人问：“怎么样，相中没有？”小伙子说：“就是嘴太大了，嘴唇太厚。”媒人说：“这有什么不好吗？”“当然了，化起妆来多浪费口红埃”',
 'img': '',
 'name': '紫由',
 'title': '嘴大浪费口红'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '我：“妈，我想买条金毛。”妈：“什么东西？”我：“金毛猎犬，小狗八百一只。”妈：“什么狗这么贵,不行。”我：“超可爱的，养大了还能拉出去撩妹。”三秒后。。。我妈：“有卖现成大狗的吗？”',
 'img': '',
 'name': '紫由',
 'title': '有现成的吗？'}
2019-01-10 11:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_3.html>
{'content': '今天老婆回家，一脸的不高兴，随时都可能爆发出来，吃晚饭的时候，我想帮老婆刷刷碗，让他休息一会，我刚开口说：老婆，一会碗我。。她随手一个大嘴巴，：“玩你妈个头”',
 'img': '',
 'name': '紫由',
 'title': '玩个头'}
2019-01-10 11:10:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_4.html> (referer: https://www.pengfu.com/zuijurenqi_1_3.html)
2019-01-10 11:10:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '老师：如果让你选择，你会希望家人从事什么职业？\u3000\u3000'
            '学生：我的爸爸很睿智，我希望他当哲学家；我的妈妈很聪明，我希望她当数学家。\u3000\u3000'
            '老师：那么你呢？\u3000\u3000学生：我只能当企业家，因为我必须挣钱来养活我的穷爸爸和穷妈妈。',
 'img': '',
 'name': '紫由',
 'title': '企业家'}
2019-01-10 11:10:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': 'A:现在电视广告真有效\u3000\u3000B:咋的？\u3000\u3000'
            'A:昨天中午播了我们招聘仓库保安的广告，\u3000\u3000B:晚上就有人应聘了？\u3000\u3000'
            'A:晚上仓库就被人盗了QAQ',
 'img': '',
 'name': '紫由',
 'title': '被盗了'}
2019-01-10 11:10:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '小时候跟狗玩耍，被狗咬了弄破了点皮，当时怕打针没去打。我妈那时候告诉我如果不打针长大后就会变成一条狗。那时我根本不信没去打。不过到今年我终于信了，为什么当时我听妈妈的话，也不至于现在变成一条单身狗了！',
 'img': '',
 'name': '紫由',
 'title': '单身狗'}
2019-01-10 11:10:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_4.html>
{'content': '25年前我还是一个天真无邪的孩子！直到几年前出了个广告，我的人生就陷入了黑暗！我叫付言杰。。。',
 'img': '',
 'name': '紫由',
 'title': '付言杰。。。'}
2019-01-10 11:10:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:10:25 [scrapy.extensions.feedexport] INFO: Stored json feed (34 items) in: a.json
2019-01-10 11:10:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1546,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 28668,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 10, 25, 727834),
 'item_scraped_count': 34,
 'log_count/DEBUG': 39,
 'log_count/INFO': 8,
 'request_depth_max': 3,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 1, 10, 3, 10, 20, 766610)}
2019-01-10 11:10:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:15:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:15:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:15:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:15:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:15:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:15:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:15:55 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:15:55 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:15:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:15:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:15:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:58 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e0706e644.jpg',
 'name': '采妮',
 'title': '大爷这技术溜啊'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e0b3b80ed.jpg',
 'name': '采妮',
 'title': '干这行要眼疾手快'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '他横由他横，明月照大江',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3faaf4d0.jpg',
 'name': '采妮',
 'title': '他强任他强，清风抚山岗。'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e391719fa.jpg',
 'name': '采妮',
 'title': '好心疼这车橘子，就这样完了！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3aca3f45.jpg',
 'name': '采妮',
 'title': '孩子，亏你还能尿得出来…'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e08dc0b0f.jpg',
 'name': '采妮',
 'title': '这个就不用每天早上洗头了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '受到了100000点暴击。。。',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3d1bfe7c.jpg',
 'name': '采妮',
 'title': '想找喵星人玩的狗狗，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3ff89789.jpg',
 'name': '采妮',
 'title': '竹子君和牵牛花'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:15:59 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e03ecc042.jpg',
 'name': '采妮',
 'title': '猫咪正在试探二狗子的最后底线'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_3.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e4068c258.jpg',
 'name': '采妮',
 'title': '根本停不下来'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e00f57660.jpg',
 'name': '采妮',
 'title': '横店公交的日常'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e426e3906.jpg',
 'name': '采妮',
 'title': '这个大哥烦人烦人的'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '一个人在家，洗完澡后穿条内裤坐电脑前一边上网一边吃核桃，',
 'img': '',
 'name': '紫由',
 'title': '夹核桃'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '父亲叫儿子打酒，儿子问爸爸：“瓶子里不是还有吗？”爸爸摇摇头说：“太少了。”几分钟后，儿子提着瓶子回来了。父亲接过酒瓶一看，楞住了……原来酒瓶里装着大半瓶石子。儿子得意洋洋地说：“爸爸，您喝吧，乌鸦就是这样喝水的。”',
 'img': '',
 'name': '紫由',
 'title': '乌鸦喝水'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '一天上班无聊中在玩手机，突然看到老板过来了，我就匆忙把手机收起来，一不小心把手机掉地上了，我还慌乱中，老板弯腰帮我把手机捡了起来，然后跟我说了句我这辈子都能记住的话。 '
            '他说：没事，你玩你的，只要你把事情做好了，我不会说你，没必要做样子给我看，我也不喜欢别人只做样子；今天我是你老板，说不定哪天我破产，你发达了，我就要给你打工呢？做人实实在在就好……。结果第二天我因为穿运动鞋被开除了！',
 'img': '',
 'name': '紫由',
 'title': '因为穿运动鞋被开除了！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '儿子“妈妈，母亲是什么意思?”\u3000\u3000妈妈“‘母亲’就是妈妈的另一种叫法。”\u3000\u3000'
            '爸爸在一旁问：\u3000“那爸爸的另一种叫法呢?”\u3000\u3000儿子大声地说：“公亲。”',
 'img': '',
 'name': '紫由',
 'title': '在逗我吗？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '有一位小伙子，特吝啬，相亲了许多姑娘都没有成，父母很着急。这天，又委托媒人领着他去一位姑娘家相亲。相亲后，小伙子没有表态，媒人问：“怎么样，相中没有？”小伙子说：“就是嘴太大了，嘴唇太厚。”媒人说：“这有什么不好吗？”“当然了，化起妆来多浪费口红埃”',
 'img': '',
 'name': '紫由',
 'title': '嘴大浪费口红'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '我：“妈，我想买条金毛。”妈：“什么东西？”我：“金毛猎犬，小狗八百一只。”妈：“什么狗这么贵,不行。”我：“超可爱的，养大了还能拉出去撩妹。”三秒后。。。我妈：“有卖现成大狗的吗？”',
 'img': '',
 'name': '紫由',
 'title': '有现成的吗？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:00 [scrapy.core.scraper] ERROR: Error processing {'content': '老师：如果让你选择，你会希望家人从事什么职业？\u3000\u3000'
            '学生：我的爸爸很睿智，我希望他当哲学家；我的妈妈很聪明，我希望她当数学家。\u3000\u3000'
            '老师：那么你呢？\u3000\u3000学生：我只能当企业家，因为我必须挣钱来养活我的穷爸爸和穷妈妈。',
 'img': '',
 'name': '紫由',
 'title': '企业家'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_4.html> (referer: https://www.pengfu.com/zuijurenqi_1_3.html)
2019-01-10 11:16:01 [scrapy.core.scraper] ERROR: Error processing {'content': '今天老婆回家，一脸的不高兴，随时都可能爆发出来，吃晚饭的时候，我想帮老婆刷刷碗，让他休息一会，我刚开口说：老婆，一会碗我。。她随手一个大嘴巴，：“玩你妈个头”',
 'img': '',
 'name': '紫由',
 'title': '玩个头'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:01 [scrapy.core.scraper] ERROR: Error processing {'content': 'A:现在电视广告真有效\u3000\u3000B:咋的？\u3000\u3000'
            'A:昨天中午播了我们招聘仓库保安的广告，\u3000\u3000B:晚上就有人应聘了？\u3000\u3000'
            'A:晚上仓库就被人盗了QAQ',
 'img': '',
 'name': '紫由',
 'title': '被盗了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:01 [scrapy.core.scraper] ERROR: Error processing {'content': '小时候跟狗玩耍，被狗咬了弄破了点皮，当时怕打针没去打。我妈那时候告诉我如果不打针长大后就会变成一条狗。那时我根本不信没去打。不过到今年我终于信了，为什么当时我听妈妈的话，也不至于现在变成一条单身狗了！',
 'img': '',
 'name': '紫由',
 'title': '单身狗'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:01 [scrapy.core.scraper] ERROR: Error processing {'content': '25年前我还是一个天真无邪的孩子！直到几年前出了个广告，我的人生就陷入了黑暗！我叫付言杰。。。',
 'img': '',
 'name': '紫由',
 'title': '付言杰。。。'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    return json.dumps(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:16:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:16:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1546,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 28685,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 16, 1, 928475),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 34,
 'log_count/INFO': 7,
 'request_depth_max': 3,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 1, 10, 3, 15, 55, 953255)}
2019-01-10 11:16:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:16:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:16:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:16:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:16:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:16:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:16:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:16:59 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:16:59 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:16:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:16:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:17:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:01 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_2.html> (referer: https://www.pengfu.com/zuijurenqi_1_1.html)
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e0706e644.jpg',
 'name': '采妮',
 'title': '大爷这技术溜啊'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e0b3b80ed.jpg',
 'name': '采妮',
 'title': '干这行要眼疾手快'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '他横由他横，明月照大江',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3faaf4d0.jpg',
 'name': '采妮',
 'title': '他强任他强，清风抚山岗。'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e391719fa.jpg',
 'name': '采妮',
 'title': '好心疼这车橘子，就这样完了！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3aca3f45.jpg',
 'name': '采妮',
 'title': '孩子，亏你还能尿得出来…'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e08dc0b0f.jpg',
 'name': '采妮',
 'title': '这个就不用每天早上洗头了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '受到了100000点暴击。。。',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3d1bfe7c.jpg',
 'name': '采妮',
 'title': '想找喵星人玩的狗狗，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3ff89789.jpg',
 'name': '采妮',
 'title': '竹子君和牵牛花'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:02 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e03ecc042.jpg',
 'name': '采妮',
 'title': '猫咪正在试探二狗子的最后底线'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_3.html> (referer: https://www.pengfu.com/zuijurenqi_1_2.html)
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e4068c258.jpg',
 'name': '采妮',
 'title': '根本停不下来'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e00f57660.jpg',
 'name': '采妮',
 'title': '横店公交的日常'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/thumb/190109/5c35e426e3906.jpg',
 'name': '采妮',
 'title': '这个大哥烦人烦人的'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '一个人在家，洗完澡后穿条内裤坐电脑前一边上网一边吃核桃，',
 'img': '',
 'name': '紫由',
 'title': '夹核桃'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '父亲叫儿子打酒，儿子问爸爸：“瓶子里不是还有吗？”爸爸摇摇头说：“太少了。”几分钟后，儿子提着瓶子回来了。父亲接过酒瓶一看，楞住了……原来酒瓶里装着大半瓶石子。儿子得意洋洋地说：“爸爸，您喝吧，乌鸦就是这样喝水的。”',
 'img': '',
 'name': '紫由',
 'title': '乌鸦喝水'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '一天上班无聊中在玩手机，突然看到老板过来了，我就匆忙把手机收起来，一不小心把手机掉地上了，我还慌乱中，老板弯腰帮我把手机捡了起来，然后跟我说了句我这辈子都能记住的话。 '
            '他说：没事，你玩你的，只要你把事情做好了，我不会说你，没必要做样子给我看，我也不喜欢别人只做样子；今天我是你老板，说不定哪天我破产，你发达了，我就要给你打工呢？做人实实在在就好……。结果第二天我因为穿运动鞋被开除了！',
 'img': '',
 'name': '紫由',
 'title': '因为穿运动鞋被开除了！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '儿子“妈妈，母亲是什么意思?”\u3000\u3000妈妈“‘母亲’就是妈妈的另一种叫法。”\u3000\u3000'
            '爸爸在一旁问：\u3000“那爸爸的另一种叫法呢?”\u3000\u3000儿子大声地说：“公亲。”',
 'img': '',
 'name': '紫由',
 'title': '在逗我吗？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '有一位小伙子，特吝啬，相亲了许多姑娘都没有成，父母很着急。这天，又委托媒人领着他去一位姑娘家相亲。相亲后，小伙子没有表态，媒人问：“怎么样，相中没有？”小伙子说：“就是嘴太大了，嘴唇太厚。”媒人说：“这有什么不好吗？”“当然了，化起妆来多浪费口红埃”',
 'img': '',
 'name': '紫由',
 'title': '嘴大浪费口红'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '我：“妈，我想买条金毛。”妈：“什么东西？”我：“金毛猎犬，小狗八百一只。”妈：“什么狗这么贵,不行。”我：“超可爱的，养大了还能拉出去撩妹。”三秒后。。。我妈：“有卖现成大狗的吗？”',
 'img': '',
 'name': '紫由',
 'title': '有现成的吗？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:03 [scrapy.core.scraper] ERROR: Error processing {'content': '老师：如果让你选择，你会希望家人从事什么职业？\u3000\u3000'
            '学生：我的爸爸很睿智，我希望他当哲学家；我的妈妈很聪明，我希望她当数学家。\u3000\u3000'
            '老师：那么你呢？\u3000\u3000学生：我只能当企业家，因为我必须挣钱来养活我的穷爸爸和穷妈妈。',
 'img': '',
 'name': '紫由',
 'title': '企业家'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_4.html> (referer: https://www.pengfu.com/zuijurenqi_1_3.html)
2019-01-10 11:17:04 [scrapy.core.scraper] ERROR: Error processing {'content': '今天老婆回家，一脸的不高兴，随时都可能爆发出来，吃晚饭的时候，我想帮老婆刷刷碗，让他休息一会，我刚开口说：老婆，一会碗我。。她随手一个大嘴巴，：“玩你妈个头”',
 'img': '',
 'name': '紫由',
 'title': '玩个头'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:04 [scrapy.core.scraper] ERROR: Error processing {'content': 'A:现在电视广告真有效\u3000\u3000B:咋的？\u3000\u3000'
            'A:昨天中午播了我们招聘仓库保安的广告，\u3000\u3000B:晚上就有人应聘了？\u3000\u3000'
            'A:晚上仓库就被人盗了QAQ',
 'img': '',
 'name': '紫由',
 'title': '被盗了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:04 [scrapy.core.scraper] ERROR: Error processing {'content': '小时候跟狗玩耍，被狗咬了弄破了点皮，当时怕打针没去打。我妈那时候告诉我如果不打针长大后就会变成一条狗。那时我根本不信没去打。不过到今年我终于信了，为什么当时我听妈妈的话，也不至于现在变成一条单身狗了！',
 'img': '',
 'name': '紫由',
 'title': '单身狗'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:04 [scrapy.core.scraper] ERROR: Error processing {'content': '25年前我还是一个天真无邪的孩子！直到几年前出了个广告，我的人生就陷入了黑暗！我叫付言杰。。。',
 'img': '',
 'name': '紫由',
 'title': '付言杰。。。'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:17:04 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:17:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1546,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 28690,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 17, 4, 848363),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 34,
 'log_count/INFO': 7,
 'request_depth_max': 3,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 1, 10, 3, 16, 59, 823051)}
2019-01-10 11:17:04 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:17:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:17:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:17:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:17:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:17:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:17:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:17:33 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:17:33 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:17:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:17:33 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:17:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    return json.dump(item)
TypeError: dump() missing 1 required positional argument: 'fp'
2019-01-10 11:17:35 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:17:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7050,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 17, 35, 200919),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 17, 33, 400134)}
2019-01-10 11:17:35 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:19:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:19:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:19:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:19:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:19:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:19:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:19:59 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:19:59 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:19:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:19:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:20:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:20:00 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:00 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:00 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(item).decode("unicode-escape"))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PengfuItem is not JSON serializable
2019-01-10 11:20:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:20:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7060,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 20, 1, 24603),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 19, 59, 322078)}
2019-01-10 11:20:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:20:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:20:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:20:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:20:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:20:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:20:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:20:19 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:20:19 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:20:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:20:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:20:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:20:21 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:20:21 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:20:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7054,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 20, 21, 60926),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 20, 19, 277710)}
2019-01-10 11:20:21 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:24:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:24:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:24:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:24:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:24:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:24:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:24:48 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:24:48 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:24:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:24:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:24:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:24:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:24:50 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:24:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7054,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 24, 50, 264660),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 24, 48, 541079)}
2019-01-10 11:24:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:25:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:25:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:25:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:25:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:25:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:25:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:25:24 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:25:24 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:25:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:25:24 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:25:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:25:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:25:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7057,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 25, 25, 849564),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 25, 24, 57175)}
2019-01-10 11:25:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:25:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:25:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:25:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:25:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:25:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:25:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:25:59 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:25:59 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:25:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:25:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:26:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print(json.dumps(dict(item)).decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:26:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:26:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7050,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 26, 1, 42632),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 25, 59, 294987)}
2019-01-10 11:26:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:26:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:26:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:26:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:26:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:26:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:26:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:26:20 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:26:20 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:26:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:26:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:26:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u4e0d\u77e5\u95fa\u5bc6\u7684\u8bdd\u6709\u6ca1\u6709\u9053\u7406 ", "img": "", "content": "\u95fa\u871c\u5bf9\u6211\u8bf4\uff1a\u8bfb\u61c2\u7537\u4eba\u5176\u5b9e\u5f88\u7b80\u5355\uff0c\u7537\u4eba\u4e0b\u9762\u786c\u7684\u65f6\u5019\u5fc3\u5c31\u8f6f\uff0c\u4e0b\u9762\u8f6f\u7684\u65f6\u5019\u5fc3\u5c31\u786c\u3002"}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u8fd9\u624d\u662f\u5b66\u4e60\u7684\u6700\u597d\u5956\u52b1\uff01", "img": "https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u8fd9\u4e2a\u4e5f\u8981\u5e86\u795d\uff1f", "img": "https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u8fd9\u59b9\u7eb8\u611f\u5192\u4e5f\u592a\u4e25\u91cd\u4e86\u5427\uff01", "img": "https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u5c0f\u54e5\u4f60\u662f\u6765\u641e\u7b11\u7684\u5427\uff1f", "img": "https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u7ed3\u5a5a\u4e4b\u524d\u5929\u5929\u8bf4\u4f1a\u6e38\u6cf3\uff0c\u539f\u6765\u5c31\u8fd9\u6c34\u5e73\uff1f", "img": "https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u5927\u54e5\u4f60\u662f\u9a6f\u517d\u5e08\u5417\uff01", "img": "https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u8ba9\u540e\u9762\u5976\u5976\u548c\u853c\u53ef\u4eb2\u7684\u6837\u5b50\u62a2\u955c\u4e86", "img": "https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u8fd9\u84dd\u6295\u7684\u771f\u51c6", "img": "https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg", "content": ""}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{"name": "\u91c7\u59ae", "title": "\u56e0\u4e3a\u4f4e\u4f30\u4e86\u81ea\u5df1\u7684\u4f53\u578b\uff0c", "img": "https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg", "content": "\u7ed3\u679c\u7ffb\u7a97\u7684\u65f6\u5019\u5361\u4f4f\u4e86"}
2019-01-10 11:26:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000257E0FFCEB8>>
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\extensions\feedexport.py", line 224, in item_scraped
    slot.exporter.export_item(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 129, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\scrapy\exporters.py", line 66, in _get_serialized_fields
    field_iter = six.iterkeys(item)
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\six.py", line 581, in iterkeys
    return iter(d.keys(**kw))
AttributeError: 'str' object has no attribute 'keys'
2019-01-10 11:26:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:26:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7057,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 26, 22, 386951),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 26, 20, 642264)}
2019-01-10 11:26:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:27:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:27:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:27:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:27:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:27:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:27:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:27:28 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:27:28 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:27:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:27:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:27:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:27:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:27:30 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:27:30 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:27:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7060,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 27, 30, 430828),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 27, 28, 636096)}
2019-01-10 11:27:30 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:29:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:29:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:29:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:29:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:29:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:29:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:29:20 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:29:20 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:29:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:29:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:29:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:29:22 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:29:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7062,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 29, 22, 487247),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 29, 20, 713531)}
2019-01-10 11:29:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:29:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:29:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:29:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:29:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:29:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:29:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:29:40 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:29:40 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:29:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:29:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:29:42 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:29:42 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:29:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7055,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 29, 42, 167280),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 29, 40, 449041)}
2019-01-10 11:29:42 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:30:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:30:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:30:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:30:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:30:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:30:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:30:05 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:30:05 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:30:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:30:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:30:05 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-01-10 11:30:05 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-01-10 11:30:06 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-01-10 11:30:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.pengfu.com/zuijurenqi_1_1.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-01-10 11:30:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 30, 6, 765210),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 1, 10, 3, 30, 5, 220105)}
2019-01-10 11:30:06 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-01-10 11:30:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:30:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:30:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:30:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:30:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:30:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:30:27 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:30:27 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:30:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:30:27 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:30:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:30:29 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:30:29 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:30:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7067,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 30, 29, 250892),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 30, 27, 507222)}
2019-01-10 11:30:29 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:31:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:31:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:31:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_EXPORT_ENCODING': 'utf-8', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:31:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:31:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:31:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:31:20 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:31:20 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:31:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:31:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:31:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:31:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:31:22 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:31:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7061,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 31, 22, 220790),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 31, 20, 497170)}
2019-01-10 11:31:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:32:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:32:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:32:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:32:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:32:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:32:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:32:42 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:32:42 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:32:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:32:42 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:32:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:32:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:32:44 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:32:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7061,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 32, 44, 228845),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 32, 42, 458461)}
2019-01-10 11:32:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:33:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:33:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:33:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:33:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:33:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:33:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:33:14 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:33:14 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:33:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:33:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('utf8'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:16 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:33:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7064,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 33, 16, 580291),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 33, 14, 809118)}
2019-01-10 11:33:16 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:33:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:33:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:33:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:33:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:33:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:33:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:33:25 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:33:25 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:33:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:33:25 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:33:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.scraper] ERROR: Error processing {'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 39, in process_item
    print((json.dumps(dict(item))+"\n").decode('unicode_escape'))
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:33:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:33:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7061,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 33, 27, 314091),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 33, 25, 580446)}
2019-01-10 11:33:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:33:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:33:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:33:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:33:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:33:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:33:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:33:47 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:33:47 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:33:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:33:47 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:33:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:33:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:33:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:33:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:33:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:33:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:33:49 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:33:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7064,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 33, 49, 7175),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 33, 47, 325065)}
2019-01-10 11:33:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:34:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:34:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:34:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:34:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:34:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:34:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:34:10 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:34:10 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:34:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:34:10 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:34:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:34:12 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:34:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7064,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 34, 12, 380004),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 34, 10, 583228)}
2019-01-10 11:34:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:34:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:34:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:34:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:34:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:34:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:34:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:34:22 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:34:22 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:34:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:34:22 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 11:34:24 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:34:24 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:34:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7061,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 34, 24, 636775),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 34, 22, 938262)}
2019-01-10 11:34:24 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:35:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:35:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:35:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:35:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:35:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:35:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:35:59 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:35:59 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:35:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:35:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:36:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:36:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
2019-01-10 11:36:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:36:01 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:36:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7016,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 36, 1, 525919),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 35, 59, 841408)}
2019-01-10 11:36:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:36:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:36:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:36:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:36:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:36:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:36:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:36:26 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:36:26 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:36:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:36:26 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:36:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:36:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
2019-01-10 11:36:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:36:27 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:36:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7011,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 36, 27, 768427),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 36, 26, 34820)}
2019-01-10 11:36:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:36:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:36:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:36:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:36:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:36:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:36:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:36:44 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:36:44 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:36:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:36:44 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.scraper] ERROR: Error processing {'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
Traceback (most recent call last):
  File "c:\users\lester\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\lester\Desktop\python\pengfu\pengfu\pipelines.py", line 40, in process_item
    str = str.decode('utf-8')
AttributeError: 'str' object has no attribute 'decode'
2019-01-10 11:36:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:36:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7013,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 36, 46, 681303),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 10,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 36, 44, 945718)}
2019-01-10 11:36:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:37:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:37:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:37:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:37:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:37:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:37:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:37:17 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:37:17 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:37:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:37:17 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
2019-01-10 11:37:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:37:18 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:37:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7017,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 37, 18, 874514),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 37, 17, 193045)}
2019-01-10 11:37:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 11:37:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 11:37:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 11:37:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 11:37:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 11:37:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 11:37:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 11:37:31 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 11:37:31 [scrapy.core.engine] INFO: Spider opened
2019-01-10 11:37:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 11:37:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 11:37:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 11:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e07fe830b.jpg',
 'name': '采妮',
 'title': '鸡肉味，嘎嘣脆'}
2019-01-10 11:37:32 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 11:37:32 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 11:37:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7017,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 3, 37, 32, 983546),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 3, 37, 31, 307088)}
2019-01-10 11:37:32 [scrapy.core.engine] INFO: Spider closed (finished)
2019-01-10 14:00:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: pengfu)
2019-01-10 14:00:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Windows-10-10.0.16299-SP0
2019-01-10 14:00:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'pengfu', 'FEED_EXPORT_ENCODING': 'utf-8', 'FEED_FORMAT': 'json', 'FEED_URI': 'a.json', 'LOG_FILE': 'all.log', 'NEWSPIDER_MODULE': 'pengfu.spiders', 'SPIDER_MODULES': ['pengfu.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'}
2019-01-10 14:00:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-01-10 14:00:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-01-10 14:00:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-10 14:00:05 [scrapy.middleware] INFO: Enabled item pipelines:
['pengfu.pipelines.PengfuPipeline']
2019-01-10 14:00:05 [scrapy.core.engine] INFO: Spider opened
2019-01-10 14:00:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-10 14:00:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-10 14:00:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.pengfu.com/zuijurenqi_1_1.html> (referer: None)
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e41d13d75.jpg',
 'name': '采妮',
 'title': '这妹纸感冒也太严重了吧！'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '闺蜜对我说：读懂男人其实很简单，男人下面硬的时候心就软，下面软的时候心就硬。',
 'img': '',
 'name': '采妮',
 'title': '不知闺密的话有没有道理 '}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/origin/190109/5c35e65ee454e.jpg',
 'name': '采妮',
 'title': '这才是学习的最好奖励！'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image6.pengfu.com/origin/190109/5c35e738e8ba8.jpg',
 'name': '采妮',
 'title': '这个也要庆祝？'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e01ab1399.jpg',
 'name': '采妮',
 'title': '大哥你是驯兽师吗！'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35dffe50899.jpg',
 'name': '采妮',
 'title': '结婚之前天天说会游泳，原来就这水平？'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e040db5eb.jpg',
 'name': '采妮',
 'title': '让后面奶奶和蔼可亲的样子抢镜了'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e04fce9a2.jpg',
 'name': '采妮',
 'title': '小哥你是来搞笑的吧？'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3965aea5.jpg',
 'name': '采妮',
 'title': '这蓝投的真准'}
2019-01-10 14:00:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.pengfu.com/zuijurenqi_1_1.html>
{'content': '结果翻窗的时候卡住了',
 'img': 'https://image7.pengfu.com/thumb/190109/5c35e3e5421a8.jpg',
 'name': '采妮',
 'title': '因为低估了自己的体型，'}
2019-01-10 14:00:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-01-10 14:00:07 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: a.json
2019-01-10 14:00:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7088,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 10, 6, 0, 7, 607681),
 'item_scraped_count': 10,
 'log_count/DEBUG': 12,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 1, 10, 6, 0, 5, 807103)}
2019-01-10 14:00:07 [scrapy.core.engine] INFO: Spider closed (finished)
